{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdda6b27-7138-44d0-8ff7-d43cfa1c80fd",
   "metadata": {},
   "source": [
    "# **Creating Association Table**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4232f-fd3e-432d-93f9-97b0d9b06267",
   "metadata": {},
   "source": [
    "## Original Token Association Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63224405-4f31-443f-a48c-4b6f1469f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [1]\n",
    "import re\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd728cde-1547-4663-8e75-30c7a5415961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TokenassociationTables\n",
    "#  [2] new: SIMnoun_500 as pandas\n",
    "#V2.2 itterating through associations and built table \n",
    "\n",
    "target_corpus = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/targets_Brysbaert_filtered_adj.txt\"\n",
    "#target_corpus = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/SIMnoun_mini.txt\"  #try-mini corpus\n",
    "targetdata = pd.read_csv(target_corpus, sep='\\t')\n",
    "\n",
    "assoc_corpus = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/SWOW-EN.R100.csv\"\n",
    "data = {\"ASSOC\":['CS']}\n",
    "\n",
    "#itterate through assocs\n",
    "with open(assoc_corpus, \"r\") as asslist:\n",
    "    for assline in asslist:\n",
    "        assline = re.sub(r'\"', \"\", assline)  #access SWOWtargets\n",
    "        ass = assline.split(\",\")[9]       \n",
    "        ass = re.sub(r'\\n', \"\", ass) \n",
    "#itterate through targets and check if ass is in targets\n",
    "        if ass in targetdata['TARGET'].values: \n",
    "            assind = targetdata[targetdata['TARGET']== ass].index.item() #accessing target index\n",
    "            cs = targetdata['CS'].values[assind]  #accessing target CS\n",
    "            data[ass] = [cs]                      #adding cs to target\n",
    "            ass1 = assline.split(\",\")[10]  #access SWOWassocs + cleaning\n",
    "            ass1 = re.sub(r'\\n', \"\", ass1) \n",
    "            ass2 = assline.split(\",\")[11]\n",
    "            ass2 = re.sub(r'\\n', \"\", ass2) \n",
    "            ass3 = assline.split(\",\")[12]\n",
    "            ass3 = re.sub(r'\\n', \"\", ass3) \n",
    "            if ass1 not in data['ASSOC']: #assign SWOWassocs to colunns \n",
    "                data[\"ASSOC\"].append(ass1)\n",
    "            if ass2 not in data['ASSOC']:\n",
    "                data[\"ASSOC\"].append(ass2)\n",
    "            if ass3 not in data['ASSOC']:\n",
    "                data[\"ASSOC\"].append(ass3)\n",
    "df = pd.DataFrame.from_dict(data, orient ='index')\n",
    "df = df.replace([None], 0)\n",
    "print('DONE, Next Step :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe128f3-ebe6-494e-9a85-7c5f7124f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [3] Tokenassociation Tables\n",
    "#filling existent pandas(all values zero) with counts\n",
    "ASSOClist = list(data['ASSOC']) #get list of associations\n",
    "\n",
    "with open(assoc_corpus, \"r\") as assoclist:\n",
    "    for assocline in assoclist:\n",
    "            assocline = re.sub(r'\"', \"\", assocline)  #access assoctarget\n",
    "            ass = assocline.split(\",\")[9]       \n",
    "            ass = re.sub(r'\\n', \"\", ass)\n",
    "            if ass in data:\n",
    "                ass1 = assocline.split(\",\")[10]  #access R1assocs + cleaning\n",
    "                ass1 = re.sub(r'\\n', \"\", ass1)\n",
    "                assind = ASSOClist.index(ass1)          #getting column index\n",
    "                df.loc[ass,assind] += 1                 #count target-assoc pair\n",
    "                ass2 = assocline.split(\",\")[11]  #access R2assocs + cleaning\n",
    "                ass2 = re.sub(r'\\n', \"\", ass2)\n",
    "                assind = ASSOClist.index(ass2)          \n",
    "                df.loc[ass,assind] += 1\n",
    "                ass3 = assocline.split(\",\")[12]  #access R3assocs + cleaning\n",
    "                ass3 = re.sub(r'\\n', \"\", ass3)\n",
    "                assind = ASSOClist.index(ass3)          \n",
    "                df.loc[ass,assind] += 1\n",
    "#assocs as header \n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]         \n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/adj_filtered_AssocTable.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df064ea3-2c36-4f57-a8c7-641dfc20a877",
   "metadata": {},
   "source": [
    "# TokenAssoxiationTablesCHECKING OUTPUT:\n",
    "\n",
    "-targets get 100 counts each for R1 -> check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d528dd-28c6-4972-b913-905dfd9e6273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df)\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb092736-5253-45fa-b636-3915011a628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get target matches with SWOW \n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "table = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/AssocTable.csv'\n",
    "\n",
    "table = pd.read_csv(table)\n",
    "\n",
    "index_list = list(table.index.values)\n",
    "print(index_list)\n",
    "\n",
    "#getting assoc. amounts fo each target\n",
    "print(df.sum(axis = 1, skipna = True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a04c9-8d3a-454a-9523-fec95a5d52df",
   "metadata": {},
   "source": [
    "# Type Asscoiation Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f64f4-3ef3-4c13-9b1d-a40aab180372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built Type AsscoiationTable with all zeros\n",
    "# columns= from lemmatization of the tokens in the columns of the original tokenassociationtable\n",
    "# rows = targets same as in the original tokensassociationtable\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#datatype= 'extreme'\n",
    "datatype= 'filtered'\n",
    "#wordclass = 'adj'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "\n",
    "#original tokenassociationtables\n",
    "assoctable = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/R1only_'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "tokensassoctable = list(assoctable.columns)\n",
    "lemassoctable = list(map(lemma.lemmatize, tokensassoctable)) # lemmatizing tokenfeatures so only types are left\n",
    "print(len(set(lemassoctable))-2) #number of types, unifying the types so no type is mentioned twice in list\n",
    "\n",
    "targets = list(assoctable['Unnamed: 0'])\n",
    "lentargets = len(targets)\n",
    "CS = list(assoctable['CS'])  \n",
    "\n",
    "print(len(list(assoctable['Unnamed: 0'])))\n",
    "\n",
    "\n",
    "data = pd.DataFrame(index=np.arange(len(list(assoctable['Unnamed: 0']))), columns=set(lemassoctable))  #types in columns, index by target length\n",
    "cols_to_order = ['Unnamed: 0', 'CS']\n",
    "new_columns = cols_to_order + (data.columns.drop(cols_to_order).tolist())  \n",
    "data = data[new_columns]   #setting ordered columns \n",
    "data['Unnamed: 0']=targets #assigning targets to column\n",
    "data['CS']=CS              #assigning CS to column\n",
    "data['']= np.zeros(lentargets) #adding NA column for empty R1/R2/R3\n",
    "df = data.replace([None], 0)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c15f72-6499-451b-b380-a1f2cb6773b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  [3] Typeassociation Tables\n",
    "#filling existent pandas(all values zero) with counts\n",
    "assoc_corpus = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/SWOW-EN.R100.csv\"\n",
    "ASSOClist = list(df.columns) #get list of associations\n",
    "ASSOCtarget = list(df['Unnamed: 0'])  #get list of targets\n",
    "\n",
    "with open(assoc_corpus, \"r\") as assoclist:\n",
    "    for assocline in assoclist:\n",
    "            assocline = re.sub(r'\"', \"\", assocline)  #access assoctarget\n",
    "            ass = assocline.split(\",\")[9]       \n",
    "            ass = re.sub(r'\\n', \"\", ass)\n",
    "           # print('ASS: '+ass)\n",
    "            if ass in targets:\n",
    "                ass1 = assocline.split(\",\")[10]  #access R1assocs + cleaning\n",
    "                ass1 = re.sub(r'\\n', \"\", ass1)\n",
    "               # print('ASS1: ' + str(ass1))\n",
    "                #print('ASS: '+str(ass))\n",
    "                ass1 = lemma.lemmatize(ass1)\n",
    "                assind = ASSOClist.index(ass1)          #getting column index\n",
    "                assindt = ASSOCtarget.index(ass)        #getting row index\n",
    "               # print('ASS1: ' + str(ass1))\n",
    "               # print('ASS: '+str(ass))\n",
    "                df.iloc[assindt,assind] += 1                 #count target-assoc pair\n",
    "               # ass2 = assocline.split(\",\")[11]  #access R2assocs + cleaning\n",
    "               # ass2 = re.sub(r'\\n', \"\", ass2)\n",
    "               # ass2 = lemma.lemmatize(ass2)\n",
    "               # assind = ASSOClist.index(ass2) \n",
    "                #print('ASSINDT: '+str(assindt))\n",
    "                #print('ASS1: ' + str(ass1))\n",
    "               # print('ASS2: ' + str(ass2))\n",
    "              #  df.iloc[assindt,assind] += 1\n",
    "              #  ass3 = assocline.split(\",\")[12]  #access R3assocs + cleaning\n",
    "              #  ass3 = re.sub(r'\\n', \"\", ass3)\n",
    "              #  ass3 = lemma.lemmatize(ass3)\n",
    "              #  assind = ASSOClist.index(ass3)          \n",
    "              #  df.iloc[assindt,assind] += 1\n",
    "                \n",
    "#assocs as header \n",
    "#df.columns = df.iloc[0]\n",
    "#df = df[1:]         \n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/R1only_types_'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b421e9f-8dc4-41a7-9ded-3900ac604931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57794d7a-e54e-479f-9406-4810a5804ed2",
   "metadata": {},
   "source": [
    "# TypeAssoxiationTablesCHECKING OUTPUT:\n",
    "\n",
    "-targets get 100 counts each for R1 -> check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f7ec3-519e-4ba3-bf58-b81c40c62471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if assoctbale correct\n",
    "\n",
    "#getting assoc. amounts fo each target, 100 people were asked one target in SWOW and gave 3 answers so 300 count per target \n",
    "print(df.sum(axis = 1).nsmallest(n=10))\n",
    "#print(df.nsmallest(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c194f7-24e3-4410-941e-8be85feea156",
   "metadata": {},
   "source": [
    "# Operations fixing individual stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab65ade-5208-4abd-8569-e17c26250a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing types assoctables (fixed with index_FALSE) doesnt have to be run again\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "datatype= 'extreme'\n",
    "#datatype= 'filtered'\n",
    "wordclass = 'adj'\n",
    "#wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "\n",
    "#original tokenassociationtables\n",
    "assoctable = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/types_'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "df = assoctable.drop(columns=['Unnamed: 0.1'])\n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/types_'+wordclass+'_'+datatype+'_AssocTable.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b59164-a8fe-4295-a203-9882169ba8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changig one value in SWOW\n",
    "\n",
    "import pandas as pd\n",
    "assoctable = pd.read_csv(\"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/SWOW-EN.R100.csv\")\n",
    "#print(assoctable[133802:133803])\n",
    "#assoctable.loc[133802, 'R1'] = 'pocket'\n",
    "#print(assoctable[133802:133803])\n",
    "\n",
    "#assoctable.to_csv(\"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/SWOW-EN.R100.csv\")\n",
    "assoc = assoc.replace(r'^\\s*$', np.nan, regex=True)\n",
    "assoc.to_csv(\"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/SWOW-EN.R100.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525da7f2-a8a4-466f-9a8e-91f392316715",
   "metadata": {},
   "source": [
    "# One-Hot AssociationTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022094ef-622b-4d52-9826-044df3d4c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot of token assoctables\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#datatype= 'extreme'\n",
    "datatype= 'filtered'\n",
    "#wordclass = 'adj'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "\n",
    "#original tokenassociationtables\n",
    "assoctable = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "df = assoctable.drop(columns=['Unnamed: 0', 'CS'])\n",
    "df = df<1   #booleans for the numbers \n",
    "df = df.replace({True: 0, False: 1})  #booleans in 0 and 1\n",
    "df.insert(0, 'CS', assoctable['CS'])  #CS back in dataframe\n",
    "df.insert(0, 'Unnamed: 0', assoctable['Unnamed: 0'])  #taregts back in dataframe\n",
    "\n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/one-hot_'+wordclass+'_'+datatype+'_AssocTable.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3243fc-7c77-43bb-96c2-057d17111588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot of types assoctables\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "datatype= 'extreme'\n",
    "#datatype= 'filtered'\n",
    "wordclass = 'adj'\n",
    "#wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "\n",
    "#original tokenassociationtables\n",
    "assoctable = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/types_'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "print(assoctable)\n",
    "df = assoctable.drop(columns=['Unnamed: 0', 'CS'])\n",
    "df = df<1   #booleans for the numbers \n",
    "df = df.replace({True: 0, False: 1})  #booleans in 0 and 1\n",
    "df.insert(0, 'CS', assoctable['CS'])  #CS back in dataframe\n",
    "df.insert(0, 'Unnamed: 0', assoctable['Unnamed: 0'])  #taregts back in dataframe\n",
    "print(df)\n",
    "\n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/one-hot_types_'+wordclass+'_'+datatype+'_AssocTable.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2bd8c-2eac-4b00-83d8-31a3ba3b9340",
   "metadata": {},
   "source": [
    "# Type Assoctable without NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a96b529-138c-412d-b644-8e3fad6b64c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/jupyterhub/lib64/python3.10/site-packages/pandas/core/indexes/base.py:3629\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/jupyterhub/lib64/python3.10/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/jupyterhub/lib64/python3.10/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ''",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m NAtable \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCS\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA Amount\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m NAtable[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m NAtable[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA Amount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m#dropping the NA column\u001b[39;00m\n\u001b[1;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m#dropping the last column of the table !!!!AFTER CHECKING DATATABLES LAST COLUMN\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/jupyterhub/lib64/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/jupyterhub/lib64/python3.10/site-packages/pandas/core/indexes/base.py:3631\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3631\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3632\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3633\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3634\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3635\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ''"
     ]
    }
   ],
   "source": [
    "# droping NA columns in the type assoctables\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#datatype = 'extreme'\n",
    "datatype = 'filtered'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "df = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/R1only_types_'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "print(len(list(df.columns)))\n",
    "NAtable = pd.DataFrame(columns=['CS','NA Amount'])\n",
    "NAtable['CS'] = df['CS']\n",
    "NAtable['NA Amount'] = df['NA']\n",
    "df = df.drop('NA', axis=1)  #dropping the NA column\n",
    "df = df.drop(df.iloc[:,-1:],axis=1)  #dropping the last column of the table !!!!AFTER CHECKING DATATABLES LAST COLUMN\n",
    "print(len(list(df.columns)))\n",
    "\n",
    "\n",
    "\n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/R1only_noNAtypes_'+wordclass+'_'+datatype+'_AssocTable.csv',index=False)\n",
    "NAtable.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/R1only_NAtypes_'+wordclass+'_'+datatype+'.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46089317-0cda-419f-b3ec-0237f262f8ed",
   "metadata": {},
   "source": [
    "# L1 Normalizing without NA tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46042e1-009e-4502-b013-7e6a16934972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datatables where the sum of associations isnt equal for all targets (bc NAs deleted)\n",
    "# dividing every cell with the amount of associatins for this target\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#datatype= 'extreme'\n",
    "datatype= 'filtered'\n",
    "wordclass = 'adj'\n",
    "#wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "\n",
    "df = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/noNA'+wordclass+'_'+datatype+'_AssocTable.csv')\n",
    "cs = df['CS']\n",
    "target = df['Unnamed: 0']\n",
    "df = df.drop('CS', axis=1)  #dropping the CS column\n",
    "df = df.drop('Unnamed: 0', axis=1)  #dropping the Target column\n",
    "\n",
    "#data = preprocessing.normalize(df, axis=1) # normalize df rows\n",
    "df = df.div(df.sum(axis=1), axis=0) # summing row and dividing row by that sum\n",
    "df = pd.DataFrame(df, columns=df.columns)\n",
    "df.insert(0, 'CS', cs) #adding CS again\n",
    "df.insert(0, 'Unnamed: 0', target) #adding targets again\n",
    "\n",
    "df.to_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_'+datatype+'/NORMnoNA_'+wordclass+'_'+datatype+'_AssocTable.csv',index=False)             \n",
    "  \n",
    "# checking if sum of rows is CS+1.0\n",
    "print(df.sum(axis=1))\n",
    "print(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bafbb4-d0b9-4b90-9d0a-5d2fa7cc1d14",
   "metadata": {},
   "source": [
    "# Word Class Vectors\n",
    "- no NAs\n",
    "- normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd5e5c-59f9-4f66-a7c2-5063487aa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word classes as features, POS counts in each cell per target\n",
    "import pandas as pd\n",
    "\n",
    "#datatype= 'extreme'\n",
    "datatype= 'filtered'\n",
    "wordclass = 'adj'\n",
    "#wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "\n",
    "df = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/'+wordclass+'_'+datatype+'_POStable.csv')\n",
    "\n",
    "# delete NA POS tags\n",
    "df = df.drop('SYM', axis=1)  #dropping the SYM column\n",
    "df = df.drop('.', axis=1)  #dropping the SYM column\n",
    "df = df.drop(':', axis=1)  #dropping the SYM column\n",
    "df = df.drop('$', axis=1)  #dropping the SYM column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a745fc7-b490-4d68-a729-ab10a75d9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98c67a1-0de5-4486-8a4e-a33ca407427f",
   "metadata": {},
   "source": [
    "# getting stats about the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeba903-4037-4302-9fe5-0a4da2e5e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of targets before assocaition-is-in-swow filter\n",
    "import pandas as pd\n",
    "\n",
    "target_adj = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/targets_Brysbaert_filtered_adj.txt\"\n",
    "target_verb = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/targets_Brysbaert_filtered_verbs.txt\"\n",
    "target_noun = \"/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/targets_Brysbaert_filtered_nouns.txt\"\n",
    "\n",
    "target_adj = pd.read_csv(target_adj, sep='\\t')\n",
    "print('ADJ: ' +str(len(target_adj.index)))\n",
    "      \n",
    "target_verb = pd.read_csv(target_verb, sep='\\t')\n",
    "print('VERB: ' +str(len(target_verb.index)))\n",
    "      \n",
    "target_noun = pd.read_csv(target_noun, sep='\\t')\n",
    "print('NOUN: ' +str(len(target_noun.index)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cddde9-87e6-47aa-8ac1-00c6d59b0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount of targets after association-is-in-swow filter\n",
    "\n",
    "dfa = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/adj_filtered_AssocTable.csv')\n",
    "dfv = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/verbs_filtered_AssocTable.csv')\n",
    "dfn = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/nouns_filtered_AssocTable.csv')\n",
    "\n",
    "dfaex = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_extreme/adj_extreme_AssocTable.csv')\n",
    "dfvex = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_extreme/verbs_extreme_AssocTable.csv')\n",
    "dfnex = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_extreme/nouns_extreme_AssocTable.csv')\n",
    "\n",
    "\n",
    "print('ADJ: ' +str(len(dfa.index)))    \n",
    "print('VERB: ' +str(len(dfv.index)))    \n",
    "print('NOUN: ' +str(len(dfn.index)))\n",
    "\n",
    "print('ADJ: ' +str(len(dfaex.index)))    \n",
    "print('VERB: ' +str(len(dfvex.index)))    \n",
    "print('NOUN: ' +str(len(dfnex.index)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678e02f-bf2a-4a83-9ee7-45c822122776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature reduction after lemmatization\n",
    "\n",
    "dfanew = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAtypes_adj_filtered_AssocTable.csv')\n",
    "dfvnew = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAtypes_verbs_filtered_AssocTable.csv')\n",
    "dfnnew = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAtypes_nouns_filtered_AssocTable.csv')\n",
    "\n",
    "dfa = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAadj_filtered_AssocTable.csv')\n",
    "dfv = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAverbs_filtered_AssocTable.csv')\n",
    "dfn = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAnouns_filtered_AssocTable.csv')\n",
    "\n",
    "print('ADJ reduced: ' + str(len(dfanew.columns)-2) + ' / ' + str(len(dfa.columns)-2))\n",
    "print('VERB reduced: ' + str(len(dfvnew.columns)-2) + ' / ' + str(len(dfv.columns)-2))\n",
    "print('NOUN reduced: ' + str(len(dfnnew.columns)-2) + ' / ' + str(len(dfn.columns)-2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773623dc-0685-4bad-b4fa-d6570b5d9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# na reduction percentage \n",
    "from statistics import mean\n",
    "\n",
    "NAAfil = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NAadj_filtered.csv')\n",
    "NANfil = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NAnouns_filtered.csv')\n",
    "NAVfil = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NAverbs_filtered.csv')\n",
    "\n",
    "NAAfil = NAAfil['NA Amount'] /300\n",
    "NANfil = NANfil['NA Amount'] /300\n",
    "NAVfil = NAVfil['NA Amount'] /300\n",
    "\n",
    "print('Adj: ' + str(mean(NAAfil)))\n",
    "print('Verb: ' + str(mean(NAVfil)))\n",
    "print('Noun: ' + str(mean(NANfil)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4b51f-398d-497c-9215-6a871ebf204e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
