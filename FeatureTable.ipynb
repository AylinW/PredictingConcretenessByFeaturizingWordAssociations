{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81ebf0c-d651-48f3-8b88-69aa8c90fb4e",
   "metadata": {},
   "source": [
    "# Feature Modelling: Feature collection and vector building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9165e9b-0374-4c3b-a638-0c6ed1b31eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_55433/3272908476.py:49: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['HighestRF'] = dfvFAP.loc[:,[c for c in dfvFAP.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:50: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['HighestRF'] = dfnFAP.loc[:,[c for c in dfnFAP.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:51: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['HighestRF'] = dfaFAP.loc[:,[c for c in dfaFAP.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:57: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['LowestRF'] = dfvFAPNA.loc[:,[c for c in dfvFAPNA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:58: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['LowestRF']  = dfnFAPNA.loc[:,[c for c in dfnFAPNA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:59: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['LowestRF']  = dfaFAPNA.loc[:,[c for c in dfaFAPNA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:62: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['VarianceRF'] = list(dfvFAPNA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:63: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['VarianceRF'] = list(dfnFAPNA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:64: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['VarianceRF'] = list(dfaFAPNA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:73: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['AverageDistanceT-A'] = dfvTANA.loc[:,[c for c in dfvTANA.columns if c!= \"CS\"]].mean(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:74: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['AverageDistanceT-A'] = dfnTANA.loc[:,[c for c in dfnTANA.columns if c!= \"CS\"]].mean(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:75: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['AverageDistanceT-A'] = dfaTANA.loc[:,[c for c in dfaTANA.columns if c!= \"CS\"]].mean(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:78: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['HighestDistanceT-A'] = dfvTA.loc[:,[c for c in dfvTA.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:79: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['HighestDistanceT-A'] = dfnTA.loc[:,[c for c in dfnTA.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:80: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['HighestDistanceT-A'] = dfaTA.loc[:,[c for c in dfaTA.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:83: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['LowestDistanceT-A'] = dfvTANA.loc[:,[c for c in dfvTANA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:84: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['LowestDistanceT-A']  = dfnTANA.loc[:,[c for c in dfnTANA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:85: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['LowestDistanceT-A']  = dfaTANA.loc[:,[c for c in dfaTANA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:88: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['VarianceDistanceT-A'] = list(dfvTANA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:89: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['VarianceDistanceT-A'] = list(dfnTANA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:90: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['VarianceDistanceT-A'] = list(dfaTANA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:99: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['AverageDistanceA-A'] = dfvAANA.loc[:,[c for c in dfvAANA.columns if c!= \"CS\"]].mean(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:100: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['AverageDistanceA-A'] = dfnAANA.loc[:,[c for c in dfnAANA.columns if c!= \"CS\"]].mean(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:101: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['AverageDistanceA-A'] = dfaAANA.loc[:,[c for c in dfaAANA.columns if c!= \"CS\"]].mean(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:104: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['HighestDistanceA-A'] = dfvAA.loc[:,[c for c in dfvAA.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:105: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['HighestDistanceA-A'] = dfnAA.loc[:,[c for c in dfnAA.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:106: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['HighestDistanceA-A'] = dfaAA.loc[:,[c for c in dfaAA.columns if c!= \"CS\"]].max(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:109: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['LowestDistanceA-A'] = dfvAANA.loc[:,[c for c in dfvAANA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:110: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['LowestDistanceA-A']  = dfnAANA.loc[:,[c for c in dfnAANA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:111: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['LowestDistanceA-A']  = dfaAANA.loc[:,[c for c in dfaAANA.columns if c!= \"CS\"]].min(axis=1)\n",
      "/tmp/ipykernel_55433/3272908476.py:114: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfverb['VarianceDistanceA-A'] = list(dfvAANA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:115: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfnoun['VarianceDistanceA-A'] = list(dfnAANA.var(axis=1))\n",
      "/tmp/ipykernel_55433/3272908476.py:116: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfadj['VarianceDistanceA-A'] = list(dfaAANA.var(axis=1))\n"
     ]
    }
   ],
   "source": [
    "## Targets and CS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#feature types\n",
    "#cols = ['Unnamed: 0','CS','AmountLemma','AmountNA','HighestrelFreq','LowestrelFreq','VariancerelFreq','AverageCosDisT-A','HighestCosDisT-A','LowestCosDisT-A','VarianceCosDisT-A','AverageCosDisA-A','HighestCosDisA-A','LowestCosDisA-A','VarianceCosDisA-A','NounPOS','VerbPOS','AdjPOS','OtherPOS','NounrelPOS','VerbrelPOS','AdjrelPOS','OtherrelPOS']\n",
    "#cols = ['Target','CS','AmountTypes','AmountNA','HighestRF','LowestRF','VarianceRF','AverageDistanceT-A','HighestDistanceT-A','LowestDistanceT-A','VarianceDistanceT-A','AverageDistanceA-A','HighestDistanceA-A','LowestDistanceA-A','VarianceDistanceA-A','NounPOS','VerbPOS','AdjPOS']\n",
    "cols = ['Target','CS','AmountTypes','AmountNA','HighestRF','LowestRF','VarianceRF','AverageDistanceT-A','HighestDistanceT-A','LowestDistanceT-A','VarianceDistanceT-A','AverageDistanceA-A','HighestDistanceA-A','LowestDistanceA-A','VarianceDistanceA-A','VariancePOS']\n",
    "\n",
    "\n",
    "# setting feature modelling dataframe with targets and CS\n",
    "dfnFAP = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_nouns_filtered_AssocTable.csv')\n",
    "dfnoun = pd.DataFrame(index= dfnFAP.index ,columns = cols) \n",
    "dfnoun['Target'] = dfnFAP['Unnamed: 0']\n",
    "dfnoun['CS'] = dfnFAP['CS']\n",
    "\n",
    "dfaFAP = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_adj_filtered_AssocTable.csv')\n",
    "dfadj = pd.DataFrame(index= dfaFAP.index ,columns = cols) \n",
    "dfadj['Target'] = dfaFAP['Unnamed: 0']\n",
    "dfadj['CS'] = dfaFAP['CS']\n",
    "\n",
    "dfvFAP = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_verbs_filtered_AssocTable.csv')\n",
    "dfverb = pd.DataFrame(index= dfvFAP.index ,columns = cols) \n",
    "dfverb['Target'] = dfvFAP['Unnamed: 0']\n",
    "dfverb['CS'] = dfvFAP['CS']\n",
    "\n",
    "#assigning feature to general dataframe\n",
    "\n",
    "## lemma Amount \n",
    "dfnoun['AmountTypes'] = (dfnFAP.astype(bool).sum(axis=1))-2\n",
    "dfverb['AmountTypes'] = (dfvFAP.astype(bool).sum(axis=1))-2\n",
    "dfadj['AmountTypes'] = (dfaFAP.astype(bool).sum(axis=1))-2\n",
    "\n",
    "## NA Amount\n",
    "dfvNA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NAverbs_filtered.csv')\n",
    "dfnNA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NAnouns_filtered.csv')\n",
    "dfaNA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NAadj_filtered.csv')\n",
    "dfverb['AmountNA'] = dfvNA['NA Amount']\n",
    "dfnoun['AmountNA'] = dfnNA['NA Amount']\n",
    "dfadj['AmountNA'] = dfaNA['NA Amount']\n",
    "\n",
    "## relFreq Average  !!makes no sense with normalized data\n",
    "#dfverb['AverageFAP'] = dfvFAP[list(dfvFAP.columns())-['Unnamed: 0','CS']].mean(axis=1)\n",
    "#dfnoun['AverageFAP'] = dfnFAP[list(dfnFAP.columns())-['Unnamed: 0','CS']].mean(axis=1)\n",
    "#dfadj['AverageFAP'] = dfaFAP[list(dfaFAP.columns())-['Unnamed: 0','CS']].mean(axis=1)\n",
    "\n",
    "## relFreq Highest \n",
    "dfverb['HighestRF'] = dfvFAP.loc[:,[c for c in dfvFAP.columns if c!= \"CS\"]].max(axis=1)\n",
    "dfnoun['HighestRF'] = dfnFAP.loc[:,[c for c in dfnFAP.columns if c!= \"CS\"]].max(axis=1)\n",
    "dfadj['HighestRF'] = dfaFAP.loc[:,[c for c in dfaFAP.columns if c!= \"CS\"]].max(axis=1)\n",
    "\n",
    "## relFreq Lowest \n",
    "dfvFAPNA = dfvFAP.replace(0.0, np.NaN)\n",
    "dfnFAPNA = dfnFAP.replace(0.0,np.NaN)\n",
    "dfaFAPNA = dfaFAP.replace(0.0, np.NaN)\n",
    "dfverb['LowestRF'] = dfvFAPNA.loc[:,[c for c in dfvFAPNA.columns if c!= \"CS\"]].min(axis=1)\n",
    "dfnoun['LowestRF']  = dfnFAPNA.loc[:,[c for c in dfnFAPNA.columns if c!= \"CS\"]].min(axis=1)\n",
    "dfadj['LowestRF']  = dfaFAPNA.loc[:,[c for c in dfaFAPNA.columns if c!= \"CS\"]].min(axis=1)\n",
    "\n",
    "## relFreq Variance\n",
    "dfverb['VarianceRF'] = list(dfvFAPNA.var(axis=1))\n",
    "dfnoun['VarianceRF'] = list(dfnFAPNA.var(axis=1))\n",
    "dfadj['VarianceRF'] = list(dfaFAPNA.var(axis=1))\n",
    "\n",
    "## CosDisT-A Average\n",
    "dfvTA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_verbs_filtered_CosDisTable.csv')\n",
    "dfnTA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_nouns_filtered_CosDisTable.csv')\n",
    "dfaTA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_adj_filtered_CosDisTable.csv')\n",
    "dfvTANA = dfvTA.replace(0.0, np.NaN)\n",
    "dfnTANA = dfnTA.replace(0.0,np.NaN)\n",
    "dfaTANA = dfaTA.replace(0.0, np.NaN)\n",
    "dfverb['AverageDistanceT-A'] = dfvTANA.loc[:,[c for c in dfvTANA.columns if c!= \"CS\"]].mean(axis=1)\n",
    "dfnoun['AverageDistanceT-A'] = dfnTANA.loc[:,[c for c in dfnTANA.columns if c!= \"CS\"]].mean(axis=1)\n",
    "dfadj['AverageDistanceT-A'] = dfaTANA.loc[:,[c for c in dfaTANA.columns if c!= \"CS\"]].mean(axis=1)\n",
    "\n",
    "## CosDisT-A Highest\n",
    "dfverb['HighestDistanceT-A'] = dfvTA.loc[:,[c for c in dfvTA.columns if c!= \"CS\"]].max(axis=1)\n",
    "dfnoun['HighestDistanceT-A'] = dfnTA.loc[:,[c for c in dfnTA.columns if c!= \"CS\"]].max(axis=1)\n",
    "dfadj['HighestDistanceT-A'] = dfaTA.loc[:,[c for c in dfaTA.columns if c!= \"CS\"]].max(axis=1)\n",
    "\n",
    "## CosDisT-A Lowest\n",
    "dfverb['LowestDistanceT-A'] = dfvTANA.loc[:,[c for c in dfvTANA.columns if c!= \"CS\"]].min(axis=1)\n",
    "dfnoun['LowestDistanceT-A']  = dfnTANA.loc[:,[c for c in dfnTANA.columns if c!= \"CS\"]].min(axis=1)\n",
    "dfadj['LowestDistanceT-A']  = dfaTANA.loc[:,[c for c in dfaTANA.columns if c!= \"CS\"]].min(axis=1)\n",
    "\n",
    "## Variance CosDisT-A\n",
    "dfverb['VarianceDistanceT-A'] = list(dfvTANA.var(axis=1))\n",
    "dfnoun['VarianceDistanceT-A'] = list(dfnTANA.var(axis=1))\n",
    "dfadj['VarianceDistanceT-A'] = list(dfaTANA.var(axis=1))\n",
    "\n",
    "## CosDisA-A Average\n",
    "dfvAA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_verbs_filtered_CosDisTable32.csv')\n",
    "dfnAA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_nouns_filtered_CosDisTable32.csv')\n",
    "dfaAA = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_adj_filtered_CosDisTable32.csv')\n",
    "dfvAANA = dfvAA.replace(0.0, np.NaN)\n",
    "dfnAANA = dfnAA.replace(0.0,np.NaN)\n",
    "dfaAANA = dfaAA.replace(0.0, np.NaN)\n",
    "dfverb['AverageDistanceA-A'] = dfvAANA.loc[:,[c for c in dfvAANA.columns if c!= \"CS\"]].mean(axis=1)\n",
    "dfnoun['AverageDistanceA-A'] = dfnAANA.loc[:,[c for c in dfnAANA.columns if c!= \"CS\"]].mean(axis=1)\n",
    "dfadj['AverageDistanceA-A'] = dfaAANA.loc[:,[c for c in dfaAANA.columns if c!= \"CS\"]].mean(axis=1)\n",
    "\n",
    "## CosDisA-A Highest\n",
    "dfverb['HighestDistanceA-A'] = dfvAA.loc[:,[c for c in dfvAA.columns if c!= \"CS\"]].max(axis=1)\n",
    "dfnoun['HighestDistanceA-A'] = dfnAA.loc[:,[c for c in dfnAA.columns if c!= \"CS\"]].max(axis=1)\n",
    "dfadj['HighestDistanceA-A'] = dfaAA.loc[:,[c for c in dfaAA.columns if c!= \"CS\"]].max(axis=1)\n",
    "\n",
    "## CosDisA-A Lowest \n",
    "dfverb['LowestDistanceA-A'] = dfvAANA.loc[:,[c for c in dfvAANA.columns if c!= \"CS\"]].min(axis=1)\n",
    "dfnoun['LowestDistanceA-A']  = dfnAANA.loc[:,[c for c in dfnAANA.columns if c!= \"CS\"]].min(axis=1)\n",
    "dfadj['LowestDistanceA-A']  = dfaAANA.loc[:,[c for c in dfaAANA.columns if c!= \"CS\"]].min(axis=1)\n",
    "\n",
    "## CosDisA-A Variance\n",
    "dfverb['VarianceDistanceA-A'] = list(dfvAANA.var(axis=1))\n",
    "dfnoun['VarianceDistanceA-A'] = list(dfnAANA.var(axis=1))\n",
    "dfadj['VarianceDistanceA-A'] = list(dfaAANA.var(axis=1))\n",
    "\n",
    "## POS Noun Lemma amount POS count\n",
    "dfn = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NoUnknownNoNAtypes_nouns_filtered_POStable.csv')\n",
    "dfv = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NoUnknownNoNAtypes_verbs_filtered_POStable.csv')\n",
    "dfa = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NoUnknownNoNAtypes_adj_filtered_POStable.csv')\n",
    "\"\"\"\n",
    "dfnoun['NounPOS'] = dfn['NOUN']\n",
    "dfverb['NounPOS']= dfv['NOUN']\n",
    "dfadj['NounPOS'] = dfa['NOUN']\n",
    "## POS Verb Lemma amount POS count\n",
    "dfnoun['VerbPOS'] = dfn['VERB']\n",
    "dfverb['VerbPOS']  = dfv['VERB']\n",
    "dfadj['VerbPOS']  = dfa['VERB']\n",
    "## POS Adj Lemma amount POS count\n",
    "dfnoun['AdjPOS'] = dfn['ADJ']\n",
    "dfverb['AdjPOS'] = dfv['ADJ']\n",
    "dfadj['AdjPOS'] = dfa['ADJ']\n",
    "\"\"\"\n",
    "## variance of all associated wordclasses \n",
    "withoutcs = ['DET', 'ADV', 'ADP', 'PRON', 'NOUN', 'PRT','ADJ', 'NUM', 'VERB','CONJ']\n",
    "#wihtoutcsandnoun = ['DET', 'ADV', 'ADP', 'PRON', 'PRT','ADJ', 'NUM', 'VERB','CONJ']\n",
    "dfadj['VariancePOS'] = round(dfa.loc[:,withoutcs].var(axis=1,ddof=1),2) #adding row with variance of wordclass sums \n",
    "dfnoun['VariancePOS'] = round(dfn.loc[:,withoutcs].var(axis=1,ddof=1),2) #adding row with variance of wordclass sums \n",
    "dfverb['VariancePOS'] = round(dfv.loc[:,withoutcs].var(axis=1,ddof=1),2) #adding row with variance of wordclass sums \n",
    "\n",
    "\"\"\"\n",
    "nounN = list(dfn.loc[:, dfn.columns.str.startswith('N')].columns)\n",
    "nounV = list(dfv.loc[:, dfv.columns.str.startswith('N')].columns)\n",
    "nounA = list(dfa.loc[:, dfa.columns.str.startswith('N')].columns)\n",
    "## POS Verb Lemma amount POS count\n",
    "verbN = list(dfn.loc[:, dfn.columns.str.startswith('V')].columns)\n",
    "verbV = list(dfv.loc[:, dfv.columns.str.startswith('V')].columns)\n",
    "verbA = list(dfa.loc[:, dfa.columns.str.startswith('V')].columns)\n",
    "## POS Adj Lemma amount POS count\n",
    "adjN = list(dfn.loc[:, dfn.columns.str.startswith('J')].columns)\n",
    "adjV = list(dfv.loc[:, dfv.columns.str.startswith('J')].columns)\n",
    "adjA = list(dfa.loc[:, dfa.columns.str.startswith('J')].columns)\n",
    "## POS Other Lemma amount POS count\n",
    "otherN = list(dfn.filter(regex='^[^NVJ]', axis=1).columns) \n",
    "otherN.remove('CS')\n",
    "otherN.remove('Unnamed: 0')\n",
    "otherV = list(dfv.filter(regex='^[^NVJ]', axis=1).columns)\n",
    "otherV.remove('CS')\n",
    "otherV.remove('Unnamed: 0')\n",
    "otherA = list(dfa.filter(regex='^[^NVJ]', axis=1).columns) \n",
    "otherA.remove('CS')\n",
    "otherA.remove('Unnamed: 0')\n",
    "\n",
    "# assigning the rownormalized lemmaPOS amounts to tbe table\n",
    "dfverb['NounPOS'] = dfv[nounV].sum(axis=1) / (dfv[nounV].sum(axis=1) + dfv[verbV].sum(axis=1) + dfv[adjV].sum(axis=1) + dfv[otherV].sum(axis=1))\n",
    "dfnoun['NounPOS'] = dfn[nounN].sum(axis=1) / (dfn[nounN].sum(axis=1) + dfn[verbN].sum(axis=1) + dfn[adjN].sum(axis=1) + dfn[otherN].sum(axis=1))\n",
    "dfadj['NounPOS'] = dfa[nounA].sum(axis=1) / (dfa[nounA].sum(axis=1) + dfa[verbA].sum(axis=1) + dfa[adjA].sum(axis=1) + dfa[otherA].sum(axis=1))\n",
    "dfverb['VerbPOS'] = dfv[verbV].sum(axis=1) / (dfv[nounV].sum(axis=1) + dfv[verbV].sum(axis=1) + dfv[adjV].sum(axis=1) + dfv[otherV].sum(axis=1))\n",
    "dfnoun['VerbPOS'] = dfn[verbN].sum(axis=1)  / (dfn[nounN].sum(axis=1) + dfn[verbN].sum(axis=1) + dfn[adjN].sum(axis=1) + dfn[otherN].sum(axis=1))\n",
    "dfadj['VerbPOS'] = dfa[verbA].sum(axis=1) / (dfa[nounA].sum(axis=1) + dfa[verbA].sum(axis=1) + dfa[adjA].sum(axis=1) + dfa[otherA].sum(axis=1))\n",
    "dfverb['AdjPOS'] = dfv[adjV].sum(axis=1) / (dfv[nounV].sum(axis=1) + dfv[verbV].sum(axis=1) + dfv[adjV].sum(axis=1) + dfv[otherV].sum(axis=1))\n",
    "dfnoun['AdjPOS'] = dfn[adjN].sum(axis=1) / (dfn[nounN].sum(axis=1) + dfn[verbN].sum(axis=1) + dfn[adjN].sum(axis=1) + dfn[otherN].sum(axis=1))\n",
    "dfadj['AdjPOS'] = dfa[adjA].sum(axis=1) / (dfa[nounA].sum(axis=1) + dfa[verbA].sum(axis=1) + dfa[adjA].sum(axis=1) + dfa[otherA].sum(axis=1))\n",
    "dfverb['OtherPOS'] = dfv[otherV].sum(axis=1) / (dfv[nounV].sum(axis=1) + dfv[verbV].sum(axis=1) + dfv[adjV].sum(axis=1) + dfv[otherV].sum(axis=1))\n",
    "dfnoun['OtherPOS'] = dfn[otherN].sum(axis=1) / (dfn[nounN].sum(axis=1) + dfn[verbN].sum(axis=1) + dfn[adjN].sum(axis=1) + dfn[otherN].sum(axis=1))\n",
    "dfadj['OtherPOS'] = dfa[otherA].sum(axis=1) / (dfa[nounA].sum(axis=1) + dfa[verbA].sum(axis=1) + dfa[adjA].sum(axis=1) + dfa[otherA].sum(axis=1))\n",
    "\n",
    "## relPOS Noun Association amount POS relative freq\n",
    "dfn = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_nouns_filtered_POStable.csv')\n",
    "dfv = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_verbs_filtered_POStable.csv')\n",
    "dfa = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_adj_filtered_POStable.csv')\n",
    "nounN = list(dfn.loc[:, dfn.columns.str.startswith('N')].columns)\n",
    "nounV = list(dfv.loc[:, dfv.columns.str.startswith('N')].columns)\n",
    "nounA = list(dfa.loc[:, dfa.columns.str.startswith('N')].columns)\n",
    "dfverb['NounrelPOS'] = dfv[nounV].sum(axis=1)\n",
    "dfnoun['NounrelPOS'] = dfn[nounN].sum(axis=1)\n",
    "dfadj['NounrelPOS'] = dfa[nounA].sum(axis=1)\n",
    "## relPOS Verb Association amount POS relative freq\n",
    "verbN = list(dfn.loc[:, dfn.columns.str.startswith('V')].columns)\n",
    "verbV = list(dfv.loc[:, dfv.columns.str.startswith('V')].columns)\n",
    "verbA = list(dfa.loc[:, dfa.columns.str.startswith('V')].columns)\n",
    "dfverb['VerbrelPOS'] = dfv[verbV].sum(axis=1)\n",
    "dfnoun['VerbrelPOS'] = dfn[verbN].sum(axis=1)\n",
    "dfadj['VerbrelPOS'] = dfa[verbA].sum(axis=1)\n",
    "## relPOS Adj Association amount POS relative freq\n",
    "adjN = list(dfn.loc[:, dfn.columns.str.startswith('J')].columns)\n",
    "adjV = list(dfv.loc[:, dfv.columns.str.startswith('J')].columns)\n",
    "adjA = list(dfa.loc[:, dfa.columns.str.startswith('J')].columns)\n",
    "dfverb['AdjrelPOS'] = dfv[adjV].sum(axis=1)\n",
    "dfnoun['AdjrelPOS'] = dfn[adjN].sum(axis=1)\n",
    "dfadj['AdjrelPOS'] = dfa[adjA].sum(axis=1)\n",
    "## relPOS Other Association amount POS relative freq\n",
    "otherN = list(dfn.filter(regex='^[^NVJ]', axis=1).columns) \n",
    "otherN.remove('CS')\n",
    "otherN.remove('Unnamed: 0')\n",
    "otherV = list(dfv.filter(regex='^[^NVJ]', axis=1).columns)\n",
    "otherV.remove('CS')\n",
    "otherV.remove('Unnamed: 0')\n",
    "otherA = list(dfa.filter(regex='^[^NVJ]', axis=1).columns) \n",
    "otherA.remove('CS')\n",
    "otherA.remove('Unnamed: 0')\n",
    "dfverb['OtherrelPOS'] = dfv[otherV].sum(axis=1)\n",
    "dfnoun['OtherrelPOS'] = dfn[otherN].sum(axis=1)\n",
    "dfadj['OtherrelPOS'] = dfa[otherA].sum(axis=1)\n",
    "\"\"\"\n",
    "\n",
    "dfverb.to_csv('/compLing/students/hiwi-theses/projects/aylin.wahl/verbs_FeatureTableNewPOSVariance.csv',index=False)\n",
    "dfnoun.to_csv('/compLing/students/hiwi-theses/projects/aylin.wahl/nouns_FeatureTableNewPOSVariance.csv',index=False)\n",
    "dfadj.to_csv('/compLing/students/hiwi-theses/projects/aylin.wahl/adj_FeatureTableNewPOSVariance.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce899e2b-7aef-4a24-93cd-2bad7563c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "## POS Noun Lemma amount POS count\n",
    "dfn = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NoUnknownNoNAtypes_nouns_filtered_POStable.csv')\n",
    "dfv = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NoUnknownNoNAtypes_verbs_filtered_POStable.csv')\n",
    "dfa = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NoUnknownNoNAtypes_adj_filtered_POStable.csv')\n",
    "nounN = dfn['NOUN']\n",
    "nounV = dfv['NOUN']\n",
    "nounA = dfa['NOUN']\n",
    "## POS Verb Lemma amount POS count\n",
    "verbN = dfn['VERB']\n",
    "verbV = dfv['VERB']\n",
    "verbA = dfa['VERB']\n",
    "## POS Adj Lemma amount POS count\n",
    "adjN = dfn['ADJ']\n",
    "adjV = dfv['ADJ']\n",
    "adjA = dfa['ADJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32319e8-7d57-4fd6-a36e-70c8409a1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba389823-3c5a-4a78-ab64-68166addf77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343279dd-8a83-4df0-a09a-d60bd4ceaa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Associations Amount??? \n",
    "## amount of asscoiations for a target without NAs, divided by 300? same as amount of NA?\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dfn = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAnouns_filtered_AssocTable.csv')\n",
    "\n",
    "dfa = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAadj_filtered_AssocTable.csv')\n",
    "\n",
    "dfv = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/noNAverbs_filtered_AssocTable.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c56c1-26a8-42e4-8471-a61ccb86f1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
