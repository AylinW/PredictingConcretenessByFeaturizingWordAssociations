{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cca5761-6a34-451a-85b3-d14a89d1af4f",
   "metadata": {},
   "source": [
    "# Linear Regression: ElasicNet penalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd9747-7b25-4558-a0d0-3908f5e382ba",
   "metadata": {},
   "source": [
    "## New Version: K-fold + Fold-wise: Test on one fold, Train on the rest, with spearman correlation per fold averaged\n",
    "\n",
    "- ElasticNet penalization\n",
    "- perforance measures: R2, MAE, spearman rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06869f-75df-48f8-bd08-0e140c8bc1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import arange\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c0b75d-d3ff-47de-a868-88d722392c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into N folds\n",
    "\n",
    "dataset = 'filtered'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "foldN = 10\n",
    "\n",
    "df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_'+wordclass+'_'+dataset+'_CosDisTable32.csv'\n",
    "#df= '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_'+wordclass+'_filtered_POStable.csv'\n",
    "#df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_'+wordclass+'_'+dataset+'_CosDisTable.csv'\n",
    "#df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_' +dataset+'/'+'NORMnoNAtypes_'+wordclass+'_'+dataset+'_AssocTable.csv'\n",
    "df = pd.read_csv(df)\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "#df = df.to_numpy()\n",
    "\n",
    "#name folds in kfold column\n",
    "from sklearn import model_selection\n",
    "kf = model_selection.KFold(n_splits=foldN)   # initiate the k-fold class from model_selection module\n",
    "for fold, (trn_, val_) in enumerate(kf.split(X=df)):  # fill the new kfold column\n",
    "    df.loc[val_, 'kfold'] = fold\n",
    "#split dataset df0 up to df(foldN-1)\n",
    "folds = []\n",
    "for num in range(0,foldN):\n",
    "    globals()['df'+str(num)] = df[df['kfold'] == num]\n",
    "    globals()['df'+str(num)] = globals()['df'+str(num)].drop(['kfold'],axis=1) #delete kfold column\n",
    "    folds.append(globals()['df'+str(num)])  #list with the folddataframes\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LinElasticNet_Stats.txt\", \"a\") as f:\n",
    "    print('New Version: K-fold + Fold-wise',file=f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+str(foldN)+': (fullamount,X-1=featureamount) '+str(df.shape),file =f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+str(foldN)+': (foldamount,X-1=featureamount) '+str(df0.shape),file=f)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71588714-2e11-4ffc-aa10-55fd8433e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop: ElasticNet Regression training on foldN-1, prediction on leftout fold, spearmancorrelation for those predictions\n",
    "\n",
    "\n",
    "#ElasticNet REGRESSION WITH GRIDSEARCH HYPERPARAMETERS\n",
    "r2 = []\n",
    "mae = []\n",
    "spearmancorr = []\n",
    "spearmanp = []\n",
    "kendallp = []\n",
    "kendallcorr = []\n",
    "bestestimator = []\n",
    "bestscore = []\n",
    "bestparams = []\n",
    "bestindex = []\n",
    "score = []\n",
    "\n",
    "for i in range(0,len(folds)):\n",
    "    # getting train and test folds for this itteration\n",
    "    print('TESTED FOLD INDEX:' + str(i))\n",
    "    subfolds = folds.copy() #copy folds dataframes \n",
    "    del subfolds[i]         #delete testing dataframe\n",
    "    train = pd.concat(subfolds)  #concat all dataframes except testing one for training\n",
    "    train = train.to_numpy()\n",
    "    test = folds[i].to_numpy()  #get testing fold\n",
    "    X = train[:, 1:]    #assoc vectors: predictors\n",
    "    y = train[:, 0]     #CS: response variable\n",
    "    Xtest = test[:, 1:] #assoc vectors: predictors\n",
    "    ytest = test[:, 0]  #CS: response variable\n",
    "    \n",
    "    # ElasticNet REGRESSION\n",
    "    alphas = [1e-05]        # arange(1e-6, 1e-4, 5e-5) \n",
    "    l1ratio = [0]    # 0 means L2 peanlty, 1 means L1 penalty, between mix\n",
    "    tol = [1e-2]     # optimization tolerance (with 1e-4 not converging)\n",
    "    params = [{ 'alpha' : alphas,\n",
    "               'l1_ratio' : l1ratio,\n",
    "               'tol' : tol\n",
    "              }]\n",
    "    model = ElasticNet(copy_X = True, max_iter = 1000, selection ='random', random_state = 1)  #define model\n",
    "    # grid searching through best hyperparameters, cv is set to do no crossvalidation, refit does fit the model with the best parameters so model can be used for prediction afterwards\n",
    "    cv = GridSearchCV(model, param_grid=params, cv=[(slice(None), slice(None))],scoring='neg_mean_absolute_error', return_train_score= False,refit=True)\n",
    "    cv.fit(X,y)\n",
    "    bestestimator.append(cv.best_estimator_)\n",
    "    bestscore.append(cv.best_score_)\n",
    "    bestparams.append(cv.best_params_)\n",
    "    bestindex.append(cv.cv_results_['params'][cv.best_index_])\n",
    "    sc = cv.score(X,y)\n",
    "    score.append(sc)\n",
    "\n",
    "    # Predicting test fold\n",
    "    #setting up output dictionary\n",
    "    out = {'CS HUMAN': [],'CS MODEL': []}\n",
    "    out = defaultdict(list)\n",
    "    #itterating through vectors\n",
    "    v = 0\n",
    "    while v<= (test.shape[0]-1):\n",
    "        vector = Xtest[v,:]\n",
    "        pred = round(float(cv.predict([vector])),2)\n",
    "        out['CS MODEL'].append(pred)             #adding predicted value\n",
    "        out['CS HUMAN'].append(ytest[v])         #adding human CS\n",
    "        v += 1\n",
    "    \n",
    "    #correlation measures of human and model concreteness scores\n",
    "    corr,pval = spearmanr(out['CS HUMAN'],out['CS MODEL'])\n",
    "    corr1,pval1 = kendalltau(out['CS HUMAN'],out['CS MODEL'])\n",
    "    rtwo = r2_score(out['CS HUMAN'],out['CS MODEL'])\n",
    "    r2.append(round(rtwo,3))\n",
    "    mae.append(mean_absolute_error(out['CS HUMAN'],out['CS MODEL']))\n",
    "    spearmancorr.append(round(corr,3))\n",
    "    spearmanp.append(pval)\n",
    "    kendallp.append(pval1)\n",
    "    kendallcorr.append(round(corr1,3))\n",
    "    print('SPEARMAN CORRELATION: '+ str(corr))\n",
    "    print('R2: ' + str(rtwo))\n",
    "    print('MAE: ' + str(mean_absolute_error(out['CS HUMAN'],out['CS MODEL'])))\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LinElasticNet_Stats.txt\", \"a\") as f:\n",
    "#if close to -1/1 both scores are pos/neg correlating, if p-value smaller 0.05 correl statistically significant\n",
    "    #print('Best Estimator: '+str(cv.best_estimator_),file=f)\n",
    "    print('Scorer: '+str(cv.scorer_),file=f)\n",
    "    print('Number of Splits: '+str(cv.n_splits_),file=f)\n",
    "    print('Number of Features: '+str(cv.n_features_in_),file=f)\n",
    "    print('Best Scores: ' + str(bestscore), file=f)\n",
    "    print('Best Scores Mean: ' + str(mean(bestscore)), file=f)\n",
    "    print('Best Params: ' + str(bestparams), file=f)\n",
    "    print('Seconds for Best fitting: '+str(cv.refit_time_),file=f)\n",
    "    print('Spearman correaltion: ' + str(spearmancorr), file=f)\n",
    "    print('Spearman corr Mean: ' + str(mean(spearmancorr)), file=f)\n",
    "    print('Spearman Stddev.: '+str(stdev(spearmancorr)),file=f)\n",
    "    print('Spearman p-value: ' + str(mean(spearmanp)), file=f)\n",
    "    print('Spearman p-value Mean: ' + str(spearmanp), file=f)\n",
    "    print('Kendall correlation: ' + str(kendallcorr), file=f)\n",
    "    print('Kendall corr Mean: ' + str(mean(kendallcorr)), file=f)\n",
    "    print('Kendall Stddev.: '+str(stdev(kendallcorr)),file=f)\n",
    "    print('Kendall p-value: ' + str(kendallp), file=f)\n",
    "    print('Kendall p-value Mean: ' + str(mean(kendallp)), file=f)\n",
    "    print('MeanAbsoluteError on testdata: '+str(mae),file=f)\n",
    "    print('Mean of MeanAbsoluteError on testdata: '+str(mean(mae)),file=f)\n",
    "    print('R2 on testdata: ' + str(r2), file=f)\n",
    "    print('R2 Mean on testdata: ' + str(mean(r2)), file=f) \n",
    "    print('Score R2 on traindata: '+str(score),file=f)\n",
    "    print('Best Estimator: '+ str(bestestimator),file=f)    #see if always the same then enable the one above without listing\n",
    "    print('Best Parametersettings: ' +str(bestindex),file=f)\n",
    "    print(\"--------------------------------------------------------------------\",file=f)\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/CVRESULTSM32_noNAfinaltypes_LinElasticNet.txt\", \"a\") as f:\n",
    "    print('K-fold ElasticNet, Linear, '+wordclass+', '+str(foldN),file=f)\n",
    "    print('alphas: '+str(alphas)+', l1-ratio: '+str(l1ratio)+', tol: '+str(tol),file=f)\n",
    "    print(cv.cv_results_,file=f)\n",
    "    print('----------------------------------------------------------------------------------------------------------',file=f)\n",
    "\n",
    "print('FINISHED :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8a750-8feb-4001-89f7-9a830a10ad97",
   "metadata": {},
   "source": [
    "## New Version: 1-Fold - Extreme Set: Test on every Nth datapoint of the extreme dataset, Training on filtered dataset minus the extremes for testing, spearman on the predictions of the extreme testset\n",
    "\n",
    "- penalization ElasticNet\n",
    "- performance measures: MAE, speramn rho, R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cf797-5364-44b0-a03d-273b683e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import arange\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6258fe1-05bb-455a-b4e7-81a6fa63433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect every nth out of extreme dataset as test\n",
    "\n",
    "dataset = 'extreme'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "nth = 4\n",
    "\n",
    "\n",
    "df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_' +dataset+'/'+'NORMnoNAtypes_'+wordclass+'_'+dataset+'_AssocTable.csv'\n",
    "train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable32.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_'+wordclass+'_filtered_POStable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_'+wordclass+'_filtered_AssocTable.csv'\n",
    "train = pd.read_csv(train)\n",
    "print(train.shape)\n",
    "df = pd.read_csv(df)\n",
    "\n",
    "#get every nth abst and conc target of extreme\n",
    "abst = df.loc[df['CS'] < 2.5,:]\n",
    "conc = df.loc[df['CS'] > 2.5,:]\n",
    "target = []\n",
    "target.append(abst.iloc[::nth, :] ) #select every nth row and add dataframe to list\n",
    "target.append(conc.iloc[::nth, :] ) #select every nth row and add dataframe to list\n",
    "target = pd.concat(target)\n",
    "print(target.shape)\n",
    "testtargets = list(target['Unnamed: 0']) # get test targets\n",
    "\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets:\n",
    "    test = test.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test.shape)\n",
    "\n",
    "# delete testtargets out of filtered train dataframe\n",
    "for i in testtargets:   #itterating through test targets\n",
    "    train.drop(train.loc[train['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print(train.shape)\n",
    "#shuffle and clean train and test\n",
    "train = train.drop(['Unnamed: 0'], axis=1) #drop targets for regression \n",
    "test = test.drop(['Unnamed: 0'], axis=1) #drop targets for regression\n",
    "train = train.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "test = test.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LinElasticNet_Stats.txt\", \"a\") as f:\n",
    "    print('New Version: 1-Fold - Extreme Set',file=f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (trainamount,X-1=featureamount) '+str(train.shape),file =f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (testamount,X-1=featureamount) '+str(test.shape),file=f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93bf220-21a2-4e87-8a50-63de6cf25f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression: test on 1/n of dataframe and training on rest, spearmancollection for those predictions\n",
    " \n",
    "X = train[:, 1:]    #assoc vectors: predictors\n",
    "y = train[:, 0]     #CS: response variable\n",
    "Xtest = test[:, 1:] #assoc vectors: predictors\n",
    "ytest = test[:, 0]  #CS: response variable\n",
    "\n",
    "# ElasticNet REGRESSION\n",
    "alphas = [1e-4]        # arange(1e-6, 1e-4, 5e-5) \n",
    "l1ratio = [0.75]    # 0 means L2 peanlty, 1 means L1 penalty, between mix\n",
    "tol = [1e-2]     # optimization tolerance (with 1e-4 not converging)\n",
    "params = [{ 'alpha' : alphas,\n",
    "            'l1_ratio' : l1ratio,\n",
    "            'tol' : tol\n",
    "        }]\n",
    "model = ElasticNet(copy_X = True, max_iter = 1000, selection ='random', random_state = 1)  #define model\n",
    "# grid searching through best hyperparameters, cv is set to do no crossvalidation, refit does fit the model with the best parameters so model can be used for prediction afterwards\n",
    "cv = GridSearchCV(model, param_grid=params, cv=[(slice(None), slice(None))],scoring='neg_mean_absolute_error', return_train_score= False,refit=True)\n",
    "cv.fit(X,y)\n",
    "\n",
    "# Predicting test fold\n",
    "#setting up output dictionary\n",
    "out = {'CS HUMAN': [],'CS MODEL': []}\n",
    "out = defaultdict(list)\n",
    "#itterating through vectors\n",
    "v = 0\n",
    "while v<= (test.shape[0]-1):\n",
    "    vector = Xtest[v,:]\n",
    "    pred = round(float(cv.predict([vector])),2)\n",
    "    out['CS MODEL'].append(pred)             #adding predicted value\n",
    "    out['CS HUMAN'].append(ytest[v])         #adding human CS\n",
    "    v += 1\n",
    "\n",
    "# Correaltion measures on all predicted CS values in 'out'\n",
    "#correlation measures of human and model concreteness scores\n",
    "corr,pval = spearmanr(out['CS HUMAN'],out['CS MODEL'])\n",
    "corr1,pval1 = kendalltau(out['CS HUMAN'],out['CS MODEL'])\n",
    "#print(out)\n",
    "print('SPEARMAN CORRELATION: '+ str(corr))\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LinElasticNet_Stats.txt\", \"a\") as f:\n",
    "#if close to -1/1 both scores are pos/neg correlating, if p-value smaller 0.05 correl statistically significant\n",
    "    print('Scorer: '+str(cv.scorer_),file=f)\n",
    "    print('Number of Splits: '+str(cv.n_splits_),file=f)\n",
    "    print('Number of Features: '+str(cv.n_features_in_),file=f)\n",
    "    print('Best Scores: ' + str(cv.best_score_), file=f)\n",
    "    print('Best Params: ' + str(cv.best_params_), file=f)\n",
    "    print('Seconds for Best fitting: '+str(cv.refit_time_),file=f)\n",
    "    print('Spearman correaltion: ' + str(corr), file=f)\n",
    "    print('Spearman p-value: ' + str(pval), file=f)\n",
    "    print('Kendall correlation: ' + str(corr1), file=f)\n",
    "    print('Kendall p-value: ' + str(pval1), file=f)\n",
    "    print('MeanAbsoluteError on testdata: '+str(mean_absolute_error(out['CS HUMAN'],out['CS MODEL'])),file=f)\n",
    "    print('R2 on testdata: ' + str(r2_score(out['CS HUMAN'],out['CS MODEL'])), file=f)\n",
    "    print('Score R2 on traindata: '+str(cv.score(X,y)),file=f)\n",
    "    print('Best Estimator: '+ str(cv.best_estimator_),file=f)\n",
    "    print('Best Parametersettings: ' +str(cv.cv_results_['params'][cv.best_index_]),file=f)\n",
    "    print(\"--------------------------------------------------------------------\",file=f)\n",
    "\n",
    "    \n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/CVRESULTSM32_noNAfinaltypes_LinElasticNet.txt\", \"a\") as f:\n",
    "    print('1-fold ElasticNet, Linear, '+wordclass+', '+str(nth),file=f)\n",
    "    print('alphas: '+str(alphas)+', l1-ratio: '+str(l1ratio)+', tol: '+str(tol),file=f)\n",
    "    print(cv.cv_results_,file=f)\n",
    "    print('----------------------------------------------------------------------------------------------------------',file=f)\n",
    "\n",
    "print('FINISHED :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc79fc9-bc82-490b-9e28-a381d602e89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bbf6008-027f-4d93-b8da-66ea3eca931b",
   "metadata": {},
   "source": [
    "# New Version: 4-Fold - Extreme Set: Test on every Nth datapoint of the extreme dataset, Training on filtered dataset minus the extremes for testing, spearman on the predictions of the extreme testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c51642d-cc6d-4de0-90f1-0a604f16e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import arange\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statistics import mean\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca74d14-90fc-4f8c-923d-e4fc1aa5c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3698, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test1 = test1.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
      "/tmp/ipykernel_17969/34825066.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train1 Fold: (3512, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:54: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test2 = test2.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
      "/tmp/ipykernel_17969/34825066.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train2 Fold: (3512, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:77: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test3 = test3.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
      "/tmp/ipykernel_17969/34825066.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train3 Fold: (3512, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17969/34825066.py:100: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test4 = test4.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 27608)\n",
      "Train4 Fold: (3512, 27608)\n"
     ]
    }
   ],
   "source": [
    "# collect every nth out of extreme dataset as test\n",
    "\n",
    "dataset = 'extreme'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "nth = 4\n",
    "\n",
    "\n",
    "df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_' +dataset+'/'+'NORMnoNAtypes_'+wordclass+'_'+dataset+'_AssocTable.csv'\n",
    "train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable32.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_'+wordclass+'_filtered_POStable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_'+wordclass+'_filtered_AssocTable.csv'\n",
    "train = pd.read_csv(train)\n",
    "print(train.shape)\n",
    "df = pd.read_csv(df)\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD1\n",
    "abst = df.loc[df['CS'] < 2.5,:]\n",
    "conc = df.loc[df['CS'] >= 2.5,:]\n",
    "target1 = []\n",
    "target1.append(abst.iloc[::4, :] ) #select every nth row and add dataframe to list\n",
    "target1.append(conc.iloc[::4, :] ) #select every nth row and add dataframe to list\n",
    "target1 = pd.concat(target1)\n",
    "testtargets1 = list(target1['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test1 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets1:\n",
    "    test1 = test1.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test1.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train1 = train.copy()\n",
    "for i in testtargets1:   #itterating through test targets\n",
    "    train1.drop(train1.loc[train1['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "for i in testtargets1:   #itterating through test targets\n",
    "    if i in list(abst['Unnamed: 0']):\n",
    "        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "    else:\n",
    "        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train1 Fold: '+str(train1.shape))\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD2\n",
    "target2 = []\n",
    "target2.append(abst.iloc[::3, :] ) #select every nth row and add dataframe to list\n",
    "target2.append(conc.iloc[::3, :] ) #select every nth row and add dataframe to list\n",
    "target2 = pd.concat(target2)\n",
    "testtargets2 = list(target2['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test2 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets2:\n",
    "    test2 = test2.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test2.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train2 = train.copy()\n",
    "for i in testtargets2:   #itterating through test targets\n",
    "    train2.drop(train2.loc[train2['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "for i in testtargets2:   #itterating through test targets\n",
    "    if i in list(abst['Unnamed: 0']):\n",
    "        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "    else:\n",
    "        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train2 Fold: '+str(train2.shape))\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD3\n",
    "target3 = []\n",
    "target3.append(abst.iloc[::2, :] ) #select every nth row and add dataframe to list\n",
    "target3.append(conc.iloc[::2, :] ) #select every nth row and add dataframe to list\n",
    "target3 = pd.concat(target3)\n",
    "testtargets3 = list(target3['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test3 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets3:\n",
    "    test3 = test3.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test3.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train3 = train.copy()\n",
    "for i in testtargets3:   #itterating through test targets\n",
    "    train3.drop(train3.loc[train3['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "for i in testtargets3:   #itterating through test targets\n",
    "    if i in list(abst['Unnamed: 0']):\n",
    "        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "    else:\n",
    "        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train3 Fold: '+str(train2.shape))\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD4\n",
    "target4 = []\n",
    "target4.append(abst) #select every nth row and add dataframe to list\n",
    "target4.append(conc) #select every nth row and add dataframe to list\n",
    "target4 = pd.concat(target4)\n",
    "testtargets4 = list(target4['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test4 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets4:\n",
    "    test4 = test4.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test4.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train4 = train.copy()\n",
    "for i in testtargets4:   #itterating through test targets\n",
    "    train4.drop(train4.loc[train4['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "#for i in testtargets4:   #itterating through test targets\n",
    "#    if i in list(abst['Unnamed: 0']):\n",
    "#        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "#    else:\n",
    "#        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train4 Fold: '+str(train2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535776f9-5d0a-4f82-84c2-b77ca3577d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3514, 27607)\n",
      "(184, 27607)\n"
     ]
    }
   ],
   "source": [
    "# choosing the tetsfold for this run\n",
    "#testfold = '1'\n",
    "#testfold = '2'\n",
    "#testfold = '3'\n",
    "testfold = '4'\n",
    "\n",
    "#train = train1\n",
    "#train = train2\n",
    "#train = train3\n",
    "train = train4\n",
    "\n",
    "#test = test1\n",
    "#test = test2\n",
    "#test = test3\n",
    "test = test4\n",
    "\n",
    "#shuffle and clean train and test\n",
    "train = train.drop(['Unnamed: 0'], axis=1) #drop targets for regression \n",
    "test = test.drop(['Unnamed: 0'], axis=1) #drop targets for regression\n",
    "train = train.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "test = test.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LinElasticNet_Stats.txt\", \"a\") as f:\n",
    "    print('New Version: 1-Fold - Extreme Set',file=f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (trainamount,X-1=featureamount) '+str(train.shape),file =f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (testamount,X-1=featureamount) '+str(test.shape),file=f)\n",
    "    print('FoldNumber: ' + testfold,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efad4a7a-8e68-445e-8209-b6937b2b0ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEARMAN CORRELATION: 0.6826358847590879\n",
      "FINISHED :)\n"
     ]
    }
   ],
   "source": [
    "# regression: test on 1/n of dataframe and training on rest, spearmancollection for those predictions\n",
    " \n",
    "X = train[:, 1:]    #assoc vectors: predictors\n",
    "y = train[:, 0]     #CS: response variable\n",
    "Xtest = test[:, 1:] #assoc vectors: predictors\n",
    "ytest = test[:, 0]  #CS: response variable\n",
    "\n",
    "# ElasticNet REGRESSION\n",
    "alphas = [1e-4]        # arange(1e-6, 1e-4, 5e-5) \n",
    "l1ratio = [0.25]    # 0 means L2 peanlty, 1 means L1 penalty, between mix\n",
    "tol = [1e-2]     # optimization tolerance (with 1e-4 not converging)\n",
    "params = [{ 'alpha' : alphas,\n",
    "            'l1_ratio' : l1ratio,\n",
    "            'tol' : tol\n",
    "        }]\n",
    "model = ElasticNet(copy_X = True, max_iter = 1000, selection ='random', random_state = 1)  #define model\n",
    "# grid searching through best hyperparameters, cv is set to do no crossvalidation, refit does fit the model with the best parameters so model can be used for prediction afterwards\n",
    "cv = GridSearchCV(model, param_grid=params, cv=[(slice(None), slice(None))],scoring='neg_mean_absolute_error', return_train_score= False,refit=True)\n",
    "cv.fit(X,y)\n",
    "\n",
    "# Predicting test fold\n",
    "#setting up output dictionary\n",
    "out = {'CS HUMAN': [],'CS MODEL': []}\n",
    "out = defaultdict(list)\n",
    "#itterating through vectors\n",
    "v = 0\n",
    "while v<= (test.shape[0]-1):\n",
    "    vector = Xtest[v,:]\n",
    "    pred = round(float(cv.predict([vector])),2)\n",
    "    out['CS MODEL'].append(pred)             #adding predicted value\n",
    "    out['CS HUMAN'].append(ytest[v])         #adding human CS\n",
    "    v += 1\n",
    "\n",
    "# Correaltion measures on all predicted CS values in 'out'\n",
    "#correlation measures of human and model concreteness scores\n",
    "corr,pval = spearmanr(out['CS HUMAN'],out['CS MODEL'])\n",
    "corr1,pval1 = kendalltau(out['CS HUMAN'],out['CS MODEL'])\n",
    "#print(out)\n",
    "print('SPEARMAN CORRELATION: '+ str(corr))\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LinElasticNet_Stats.txt\", \"a\") as f:\n",
    "#if close to -1/1 both scores are pos/neg correlating, if p-value smaller 0.05 correl statistically significant\n",
    "    print('FOLD NUMBER' + testfold, file =f)\n",
    "    print('Scorer: '+str(cv.scorer_),file=f)\n",
    "    print('Number of Splits: '+str(cv.n_splits_),file=f)\n",
    "    print('Number of Features: '+str(cv.n_features_in_),file=f)\n",
    "    print('Best Scores: ' + str(cv.best_score_), file=f)\n",
    "    print('Best Params: ' + str(cv.best_params_), file=f)\n",
    "    print('Seconds for Best fitting: '+str(cv.refit_time_),file=f)\n",
    "    print('Spearman correaltion: ' + str(corr), file=f)\n",
    "    print('Spearman p-value: ' + str(pval), file=f)\n",
    "    print('Kendall correlation: ' + str(corr1), file=f)\n",
    "    print('Kendall p-value: ' + str(pval1), file=f)\n",
    "    print('MeanAbsoluteError on testdata: '+str(mean_absolute_error(out['CS HUMAN'],out['CS MODEL'])),file=f)\n",
    "    print('R2 on testdata: ' + str(r2_score(out['CS HUMAN'],out['CS MODEL'])), file=f)\n",
    "    print('Score R2 on traindata: '+str(cv.score(X,y)),file=f)\n",
    "    print('Best Estimator: '+ str(cv.best_estimator_),file=f)\n",
    "    print('Best Parametersettings: ' +str(cv.cv_results_['params'][cv.best_index_]),file=f)\n",
    "    print(\"--------------------------------------------------------------------\",file=f)\n",
    "\n",
    "    \n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/CVRESULTSM32_noNAfinaltypes_LinElasticNet.txt\", \"a\") as f:\n",
    "    print('1-fold ElasticNet, Linear, '+wordclass+', '+str(nth),file=f)\n",
    "    print('alphas: '+str(alphas)+', l1-ratio: '+str(l1ratio)+', tol: '+str(tol),file=f)\n",
    "    print(cv.cv_results_,file=f)\n",
    "    print('----------------------------------------------------------------------------------------------------------',file=f)\n",
    "\n",
    "print('FINISHED :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1a8ce-2b08-412f-9695-afa820fe4c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7885c-e3fd-4c51-b310-008afb779001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5c26a-e4b8-4783-80f8-0a73512409af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941c7ac-2c0d-49a0-9f70-3ea9979a9a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96652754-b4dc-49a1-91dc-8743f85e821b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
