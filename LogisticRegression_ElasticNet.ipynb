{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addf083d-c9f6-4178-8dab-e284cbe01577",
   "metadata": {},
   "source": [
    "# Logistic Regression predicting Concreteness Label\n",
    "\n",
    "- ElasticNet penalization\n",
    "- performance measures: F1, recall, precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bea50-ce23-4c83-9219-685f1bc41965",
   "metadata": {},
   "source": [
    "## K-fold + Fold-wise: BALANCED Test on one fold, Train on the rest, with spearman correlation per fold averagedÂ¶\n",
    "\n",
    "balanced: same amount concr and abstr in a fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17f19f-6b5f-4d32-8bd0-56b71c0d54cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import arange\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error,r2_score, classification_report\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f56e7-488b-4da4-9fa0-d516f7c92e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get splitted categorical datset BALANCED with each fold having same amount concrete and abstract\n",
    "\n",
    "# make CS categorical 1=concrete, 0=abstract\n",
    "dataset = 'filtered'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_'+wordclass+'_'+dataset+'_CosDisTable32.csv'\n",
    "#df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_'+wordclass+'_'+dataset+'_CosDisTable.csv'\n",
    "#df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_' +dataset+'/'+'NORMnoNAtypes_'+wordclass+'_'+dataset+'_AssocTable.csv'\n",
    "#df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_'+wordclass+'_filtered_POStable.csv'\n",
    "\n",
    "df = pd.read_csv(df)\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "#df = df.to_numpy()\n",
    "\n",
    "df['CS'].values[df['CS'].values < df['CS'].median()] = 0  #abstract categorical\n",
    "df['CS'].values[df['CS'].values >= df['CS'].median()] = 1 #concrete categorical\n",
    "\n",
    "#split dataset into N folds\n",
    "\n",
    "foldN = 10\n",
    "\n",
    "# separating concrete and abstract to take same percentage of concrete and abstarct into folds\n",
    "conc = df.loc[df['CS'] == 1]\n",
    "conc.reset_index(inplace = True, drop = True)\n",
    "abst = df.loc[df['CS'] == 0]\n",
    "abst.reset_index(inplace = True, drop = True)\n",
    "\n",
    "#name folds in kfold column\n",
    "from sklearn import model_selection\n",
    "kf = model_selection.KFold(n_splits=foldN)   # initiate the k-fold class from model_selection module\n",
    "for fold, (trn_, val_) in enumerate(kf.split(X=abst)):  # fill the new kfold column for abstract\n",
    "    abst.loc[val_, 'kfold'] = fold\n",
    "for fold, (trn_, val_) in enumerate(kf.split(X=conc)):  # fill the new kfold column for concrete\n",
    "    conc.loc[val_, 'kfold'] = fold\n",
    "df = pd.concat([abst,conc])   # conc and abst back into df woth kfold column\n",
    "df = df.sample(frac=1).reset_index(drop=True) #shuffeling rows of df dataframe\n",
    "\n",
    "#split dataset df0 up to df(foldN-1)\n",
    "folds = []\n",
    "for num in range(0,foldN):\n",
    "    globals()['df'+str(num)] = df[df['kfold'] == num]\n",
    "    globals()['df'+str(num)] = globals()['df'+str(num)].drop(['kfold'],axis=1) #delete kfold column\n",
    "    folds.append(globals()['df'+str(num)])  #list with the folddataframes\n",
    "\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LogElasticNet_Stats.txt\", \"a\") as f:\n",
    "    print('LogisticBalanced: K-fold + Fold-wise',file=f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+str(foldN)+': (fullamount,X-1=featureamount) '+str(df.shape),file =f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+str(foldN)+': (foldamount,X-1=featureamount) '+str(df0.shape),file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a434d61-9441-47c4-a1be-0a07d471e8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop: ElasticNet Regression training on foldN-1, prediction on leftout fold, spearmancorrelation for those predictions\n",
    "\n",
    "#ElasticNet REGRESSION WITH GRIDSEARCH HYPERPARAMETERS\n",
    "\n",
    "bestscore = []\n",
    "bestparams = []\n",
    "permatches = []\n",
    "perconc = []\n",
    "perabst = []\n",
    "meanacc = []\n",
    "classrepprecision = []\n",
    "classreprecall = []\n",
    "classrepf1 = []\n",
    "\n",
    "for i in range(0,len(folds)):\n",
    "    # getting train and test folds for this itteration\n",
    "    print('TESTED FOLD INDEX:' + str(i))\n",
    "    subfolds = folds.copy() #copy folds dataframes \n",
    "    del subfolds[i]         #delete testing dataframe\n",
    "    train = pd.concat(subfolds)  #concat all dataframes except testing one for training\n",
    "    train = train.to_numpy()\n",
    "    test = folds[i].to_numpy()  #get testing fold\n",
    "    X = train[:, 1:]    #assoc vectors: predictors\n",
    "    y = train[:, 0]     #CS: response variable\n",
    "    y = y.astype(int)\n",
    "    Xtest = test[:, 1:] #assoc vectors: predictors\n",
    "    ytest = test[:, 0]  #CS: response variable\n",
    "    ytest = ytest.astype(int)\n",
    "    \n",
    "    # LOGISTIC REGRESSION with variable LASSO(l1) or RIDGE(l2) or ElasticNet(both) penalty\n",
    "    c = [100] # high c means trust training data, low value means dont make very high values because will ot be helpful for new data (here lower C better beacuse more way more features than samples)\n",
    "    l1ratio = [0]\n",
    "    tol = [1e-02]\n",
    "    params = [{'C': c,  \n",
    "            'l1_ratio': l1ratio,\n",
    "            'tol': tol\n",
    "            }]\n",
    "    #model = Lasso(copy_X = True, tol=1e-2, max_iter = 1000, selection ='random', random_state = 1)  #define model\n",
    "    model = LogisticRegression(penalty= 'elasticnet', max_iter= 1000, solver= 'saga')   # or solver='liblinear' / penalty='l1'\n",
    "                            #  l1_ratio= 1,penalty= 'elasticnet' : l1_ratio =1 =LASSO, l1_ratio =0 =RIDGE, l1_ratio =0-1 ElasticNet\n",
    "                            # saga solver chosen becuase support of all penalties\n",
    "\n",
    "    # grid searching through best hyperparameters, cv is set to do no crossvalidation, refit does fit the model with the best parameters so model can be used for prediction afterwards\n",
    "    cv = GridSearchCV(model, param_grid = params,cv=[(slice(None), slice(None))],scoring='f1', return_train_score=False,refit=True)\n",
    "    cv.fit(X,y)\n",
    "    bestscore.append(cv.best_score_)\n",
    "    bestparams.append(cv.best_params_)\n",
    "    \n",
    "    # Predicting the test fold\n",
    "    ymodel = cv.predict(Xtest)\n",
    "    print(ymodel)\n",
    "    print(ytest)\n",
    "    #performance measure \n",
    "    matchesN = 0\n",
    "    lableabstN = 0\n",
    "    lableconcN = 0\n",
    "   # csm = out['CS MODEL']\n",
    "   # print(csm)\n",
    "   # print('Number of concrete predictions: '+str(sum(csm)))\n",
    "    print('Number of concrete predictions: '+str(sum(ymodel)))\n",
    "   # csh = out['CS HUMAN']\n",
    "    for ind, v in enumerate(ymodel):\n",
    "        if ymodel[ind] == ytest[ind]:\n",
    "            matchesN += 1\n",
    "            if v == 0:         #counting lables of matching predictions\n",
    "                lableabstN += 1\n",
    "            else:\n",
    "                lableconcN += 1\n",
    "    permatches.append(matchesN / len(ymodel))\n",
    "    perconc.append(lableconcN / sum(ymodel))\n",
    "    perabst.append(lableabstN / (len(ymodel)-sum(ymodel)))\n",
    "    meanacc.append(cv.score(Xtest, ytest))\n",
    "    precision,recall,fscore,support= score(ytest,ymodel,average='macro')\n",
    "    classrepprecision.append(precision)\n",
    "    classreprecall.append(recall)\n",
    "    classrepf1.append(fscore)\n",
    "    #classrep.append(classification_report(ytest, ymodel, output_dict=True))\n",
    "    \n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LogElasticNet_Stats.txt\", \"a\") as f:\n",
    "#if close to -1/1 both scores are pos/neg correlating, if p-value smaller 0.05 correl statistically significant\n",
    "    print('Best Estimator: '+str(cv.best_estimator_),file=f)\n",
    "    print('Scorer: '+str(cv.scorer_),file=f)\n",
    "    print('Number of Splits: '+str(cv.n_splits_),file=f)\n",
    "    print('Number of Features: '+str(cv.n_features_in_),file=f)\n",
    "    print('Best Scores: ' + str(bestscore), file=f)\n",
    "    print('Best Scores Mean: ' + str(mean(bestscore)), file=f)\n",
    "    print('Best Params: ' + str(bestparams), file=f)\n",
    "    print('Seconds for Best fitting: '+str(cv.refit_time_),file=f)\n",
    "    print('Params: '+str(cv.cv_results_['params']),file=f)\n",
    "    #print('Mean_train_score: '+str(cv.cv_results_['mean_train_score']),file=f)\n",
    "    \n",
    "    print('Matches/All predictions: ' + str(permatches),file=f)\n",
    "    print('Matches/All predictions Mean: ' + str(mean(permatches)),file=f)\n",
    "    print('Matches/All predictions Stddev: ' + str(stdev(permatches)),file=f)\n",
    "    print('Matching CONC/CONCtest: '+str(perconc),file=f)\n",
    "    print('Mean Matching CONC/CONCtest: '+str(mean(perconc)),file=f)\n",
    "    print('Stddev Matching CONC/CONCetst: '+str(stdev(perconc)),file=f)\n",
    "    print('Matching ABST/ABSTtest: '+str(perabst),file=f)\n",
    "    print('Mean Matching ABST/ABSTtest: '+str(mean(perabst)),file=f)\n",
    "    print('Stddev Matching ABST/ABSTtest: '+str(stdev(perabst)),file=f)\n",
    "    print('Mean Accuracy: ' + str(meanacc), file=f)\n",
    "    print('Mean of Mean Accuracy: ' + str(mean(meanacc)), file=f) \n",
    "    print('Mean Accuracy Stddev: ' + str(stdev(meanacc)), file=f) \n",
    "    print('ClassifReportprecision Mean: ' + str(mean(classrepprecision)), file=f)\n",
    "    print('ClassifReportprecision Stdev: ' + str(stdev(classrepprecision)), file=f)\n",
    "    print('ClassifReportrecall Mean: ' + str(mean(classreprecall)), file=f)\n",
    "    print('ClassifReportrecall Stdev: ' + str(stdev(classreprecall)), file=f)\n",
    "    print('ClassifReportF1score Mean: ' + str(mean(classrepf1)), file=f)\n",
    "    print('ClassifReportF1score Stdev: ' + str(stdev(classrepf1)), file=f)\n",
    "    print(\"--------------------------------------------------------------------\",file=f)\n",
    "    \n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/CVRESULTSM32_noNAfinaltypes_LogElasticNet.txt\", \"a\") as f:\n",
    "    print('K-fold ElasticNet, Logistic, '+wordclass+', '+str(foldN),file=f)\n",
    "    print('C: '+str(c)+', l1-ratio: '+str(l1ratio)+', tol: '+str(tol),file=f)\n",
    "    print(cv.cv_results_,file=f)\n",
    "    print('----------------------------------------------------------------------------------------------------------',file=f)\n",
    "\n",
    "print('FINISHED :)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d482d-c4f2-4976-8b18-ca4b80aa0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "blabla = pd.read_csv('/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_verbs_filtered_CosDisTable.csv')\n",
    "print(blabla[: 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3b137-b8cc-42cc-88b7-43e5e8d6a6f3",
   "metadata": {},
   "source": [
    "## New Version: 1-Fold - Extreme Set: Test on every Nth datapoint of the extreme dataset, Training on filtered dataset minus the extremes for testing, F1 on the predictions of the extreme testset\n",
    "\n",
    "- penalization ElasticNet\n",
    "- performance measures: F1, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abb8f0-5e4e-4ba0-a230-cd50f0bf53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import arange\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error,r2_score, classification_report\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0881e87-44bc-4faa-90e0-355644077641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect every nth out of extreme dataset as test\n",
    "\n",
    "dataset = 'extreme'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "nth = 4\n",
    "\n",
    "df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_' +dataset+'/'+'NORMnoNAtypes_'+wordclass+'_'+dataset+'_AssocTable.csv'\n",
    "train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable32.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_'+wordclass+'_filtered_POStable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_'+wordclass+'_filtered_AssocTable.csv'\n",
    "train = pd.read_csv(train)\n",
    "df = pd.read_csv(df)\n",
    "train['CS'].values[train['CS'].values < 2.5] = 0  #abstract categorical\n",
    "train['CS'].values[train['CS'].values >= 2.5] = 1 #concrete categorical\n",
    "df['CS'].values[df['CS'].values < 2.5] = 0  #abstract categorical\n",
    "df['CS'].values[df['CS'].values >= 2.5] = 1 #concrete categorical\n",
    "\n",
    "#get every nth abst and conc target of extreme\n",
    "abst = df.loc[df['CS'] == 0,:]\n",
    "conc = df.loc[df['CS'] == 1,:]\n",
    "target = []\n",
    "target.append(abst.iloc[::nth, :] ) #select every nth row and add dataframe to list\n",
    "target.append(conc.iloc[::nth, :] ) #select every nth row and add dataframe to list\n",
    "target = pd.concat(target)\n",
    "#target['CS'].values[target['CS'].values < 2.5] = 0  #abstract categorical\n",
    "#target['CS'].values[target['CS'].values >= 2.5] = 1 #concrete categorical\n",
    "testtargets = list(target['Unnamed: 0']) # get test targets\n",
    "\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets:\n",
    "    test = test.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)    \n",
    "    \n",
    "# delete testtargets out of filtered train dataframe\n",
    "for i in testtargets:   #itterating through test targets\n",
    "    train.drop(train.loc[train['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "\n",
    "#shuffle and clean/make categorical train and test\n",
    "train = train.drop(['Unnamed: 0'], axis=1) #drop targets for regression \n",
    "test = test.drop(['Unnamed: 0'], axis=1) #drop targets for regression\n",
    "train = train.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "test = test.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "print(train)\n",
    "print(test)\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LogElasticNet_Stats.txt\", \"a\") as f:\n",
    "    print('New Version: 1-Fold - Extreme Set',file=f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (trainamount,X-1=featureamount) '+str(train.shape),file =f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (testamount,X-1=featureamount) '+str(test.shape),file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f706d82-bae9-4a84-ba1e-6b1ede0a00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression: test on 1/n of dataframe and training on rest, spearmancollection for those predictions\n",
    " \n",
    "X = train[:, 1:]    #assoc vectors: predictors\n",
    "y = train[:, 0]     #CS: response variable\n",
    "y = y.astype(int)\n",
    "Xtest = test[:, 1:] #assoc vectors: predictors\n",
    "ytest = test[:, 0]  #CS: response variable\n",
    "ytest = ytest.astype(int)\n",
    "    \n",
    "# LOGISTIC REGRESSION with variable LASSO(l1) or RIDGE(l2) or ElasticNet(both) penalty\n",
    "c = [100] # high c means trust training data, low value means dont make very high values because will ot be helpful for new data (here lower C better beacuse more way more features than samples)\n",
    "l1ratio = [0]\n",
    "tol = [1e-02]\n",
    "params = [{'C': c,  \n",
    "        'l1_ratio': l1ratio,\n",
    "        'tol': tol\n",
    "        }]\n",
    "#model = Lasso(copy_X = True, tol=1e-2, max_iter = 1000, selection ='random', random_state = 1)  #define model\n",
    "model = LogisticRegression(penalty= 'elasticnet', max_iter= 1000, solver= 'saga')   # or solver='liblinear' / penalty='l1'\n",
    "    #  l1_ratio= 1,penalty= 'elasticnet' : l1_ratio =1 =LASSO, l1_ratio =0 =RIDGE, l1_ratio =0-1 ElasticNet\n",
    "    # saga solver chosen becuase support of all penalties\n",
    "\n",
    "    # grid searching through best hyperparameters, cv is set to do no crossvalidation, refit does fit the model with the best parameters so model can be used for prediction afterwards\n",
    "cv = GridSearchCV(model, param_grid = params,cv=[(slice(None), slice(None))],scoring='f1', return_train_score=False,refit=True)\n",
    "cv.fit(X,y)  \n",
    "\n",
    "# Predicting the test fold\n",
    "ymodel = cv.predict(Xtest)\n",
    "\n",
    "#performance measure \n",
    "matchesN = 0\n",
    "lableabstN = 0\n",
    "lableconcN = 0\n",
    "print('Number of concrete predictions: '+str(sum(ymodel)))\n",
    "for ind, v in enumerate(ymodel):\n",
    "    if ymodel[ind] == ytest[ind]:\n",
    "        matchesN += 1\n",
    "        if v == 0:         #counting lables of matching predictions\n",
    "            lableabstN += 1\n",
    "        else:\n",
    "            lableconcN += 1\n",
    "precision,recall,fscore,support= score(ytest,ymodel,average='macro')\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LogElasticNet_Stats.txt\", \"a\") as f:\n",
    "#if close to -1/1 both scores are pos/neg correlating, if p-value smaller 0.05 correl statistically significant\n",
    "    print('Best Estimator: '+str(cv.best_estimator_),file=f)\n",
    "    print('Scorer: '+str(cv.scorer_),file=f)\n",
    "    print('Number of Splits: '+str(cv.n_splits_),file=f)\n",
    "    print('Number of Features: '+str(cv.n_features_in_),file=f)\n",
    "    print('Best Scores: ' + str(cv.best_score_), file=f)\n",
    "    print('Best Params: ' + str(cv.best_params_), file=f)\n",
    "    print('Seconds for Best fitting: '+str(cv.refit_time_),file=f)\n",
    "    print('Params: '+str(cv.cv_results_['params']),file=f)\n",
    "    \n",
    "    print('Matches/All predictions: ' + str(matchesN / len(ymodel)),file=f)\n",
    "    print('Matching CONC/CONCtest: '+str(lableconcN / sum(ymodel)),file=f)\n",
    "    print('Matching ABST/ABSTtest: '+str(lableabstN / (len(ymodel)-sum(ymodel))),file=f)\n",
    "    print('Mean Accuracy: ' + str(cv.score(Xtest, ytest)), file=f)\n",
    "    print('ClassifReportprecision Mean: ' + str(precision), file=f)\n",
    "    print('ClassifReportrecall Mean: ' + str(recall), file=f)\n",
    "    print('ClassifReportF1score Mean: ' + str(fscore), file=f)\n",
    "    print('R2: ' + str(cv.score(X, y)), file=f) \n",
    "    print('ClassifReport: ' + str(classification_report(ytest, ymodel, output_dict=True)), file=f)\n",
    "    print(\"--------------------------------------------------------------------\",file=f)            \n",
    "    \n",
    "    \n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/CVRESULTSM32_noNAfinaltypes_LogElasticNet.txt\", \"a\") as f:\n",
    "    print('K-fold ElasticNet, Logistic, '+wordclass+', '+str(nth),file=f)\n",
    "    print('C: '+str(c)+', l1-ratio: '+str(l1ratio)+', tol: '+str(tol),file=f)\n",
    "    print(cv.cv_results_,file=f)\n",
    "    print('----------------------------------------------------------------------------------------------------------',file=f)\n",
    "\n",
    "\n",
    "print('FINISHED :)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ffa17-134e-4de9-87c6-ee29821bb55d",
   "metadata": {},
   "source": [
    "## New Version: 4-Fold - Extreme Set: Test on every Nth datapoint of the extreme dataset, Training on filtered dataset minus the extremes for testing, F1 on the predictions of the extreme testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80726d6b-7356-4e98-a770-8e403743b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import arange\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error,r2_score, classification_report\n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from statistics import mean, stdev\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8323d5-d4d4-47fb-921c-fbadcf502e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3698, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test1 = test1.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
      "/tmp/ipykernel_5375/3310413789.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train1 Fold: (3512, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:59: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test2 = test2.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
      "/tmp/ipykernel_5375/3310413789.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train2 Fold: (3512, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:82: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test3 = test3.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
      "/tmp/ipykernel_5375/3310413789.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train3 Fold: (3512, 27608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5375/3310413789.py:105: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  test4 = test4.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 27608)\n",
      "Train4 Fold: (3512, 27608)\n"
     ]
    }
   ],
   "source": [
    "# collect every nth out of extreme dataset as test\n",
    "\n",
    "dataset = 'extreme'\n",
    "wordclass = 'nouns'\n",
    "#wordclass = 'verbs'\n",
    "#wordclass = 'adj'\n",
    "\n",
    "nth = 4\n",
    "\n",
    "\n",
    "df = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_' +dataset+'/'+'NORMnoNAtypes_'+wordclass+'_'+dataset+'_AssocTable.csv'\n",
    "train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M32_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable32.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M4_POStable/NORMnoNAtypes_'+wordclass+'_filtered_POStable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/M3_CosDisTable/NORMnoNAtypes_'+wordclass+'_filtered_CosDisTable.csv'\n",
    "#train = '/compLing/students/hiwi-theses/data/aylin.wahl/MUDCATData/original_data/targets_Brysbaert_filtered/NORMnoNAtypes_'+wordclass+'_filtered_AssocTable.csv'\n",
    "train = pd.read_csv(train)\n",
    "print(train.shape)\n",
    "df = pd.read_csv(df)\n",
    "train['CS'].values[train['CS'].values < 2.5] = 0  #abstract categorical\n",
    "train['CS'].values[train['CS'].values >= 2.5] = 1 #concrete categorical\n",
    "df['CS'].values[df['CS'].values < 2.5] = 0  #abstract categorical\n",
    "df['CS'].values[df['CS'].values >= 2.5] = 1 #concrete categorical\n",
    "\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD1\n",
    "abst = df.loc[df['CS'] == 0,:]\n",
    "conc = df.loc[df['CS'] == 1,:]\n",
    "target1 = []\n",
    "target1.append(abst.iloc[::4, :] ) #select every nth row and add dataframe to list\n",
    "target1.append(conc.iloc[::4, :] ) #select every nth row and add dataframe to list\n",
    "target1 = pd.concat(target1)\n",
    "testtargets1 = list(target1['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test1 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets1:\n",
    "    test1 = test1.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test1.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train1 = train.copy()\n",
    "for i in testtargets1:   #itterating through test targets\n",
    "    train1.drop(train1.loc[train1['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "for i in testtargets1:   #itterating through test targets\n",
    "    if i in list(abst['Unnamed: 0']):\n",
    "        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "    else:\n",
    "        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train1 Fold: '+str(train1.shape))\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD2\n",
    "target2 = []\n",
    "target2.append(abst.iloc[::3, :] ) #select every nth row and add dataframe to list\n",
    "target2.append(conc.iloc[::3, :] ) #select every nth row and add dataframe to list\n",
    "target2 = pd.concat(target2)\n",
    "testtargets2 = list(target2['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test2 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets2:\n",
    "    test2 = test2.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test2.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train2 = train.copy()\n",
    "for i in testtargets2:   #itterating through test targets\n",
    "    train2.drop(train2.loc[train2['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "for i in testtargets2:   #itterating through test targets\n",
    "    if i in list(abst['Unnamed: 0']):\n",
    "        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "    else:\n",
    "        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train2 Fold: '+str(train2.shape))\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD3\n",
    "target3 = []\n",
    "target3.append(abst.iloc[::2, :] ) #select every nth row and add dataframe to list\n",
    "target3.append(conc.iloc[::2, :] ) #select every nth row and add dataframe to list\n",
    "target3 = pd.concat(target3)\n",
    "testtargets3 = list(target3['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test3 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets3:\n",
    "    test3 = test3.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test3.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train3 = train.copy()\n",
    "for i in testtargets3:   #itterating through test targets\n",
    "    train3.drop(train3.loc[train3['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "for i in testtargets3:   #itterating through test targets\n",
    "    if i in list(abst['Unnamed: 0']):\n",
    "        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "    else:\n",
    "        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train3 Fold: '+str(train2.shape))\n",
    "\n",
    "#get every nth abst and conc target of extreme for FOLD4\n",
    "target4 = []\n",
    "target4.append(abst) #select every nth row and add dataframe to list\n",
    "target4.append(conc) #select every nth row and add dataframe to list\n",
    "target4 = pd.concat(target4)\n",
    "testtargets4 = list(target4['Unnamed: 0']) # get test targets fold 1\n",
    "#select testtargets out of filtered dataframe to have same vectors\n",
    "test4 = pd.DataFrame(columns=list(train.columns))\n",
    "for i in testtargets4:\n",
    "    test4 = test4.append(train.loc[train['Unnamed: 0'] == i], ignore_index = True)\n",
    "print(test4.shape)\n",
    "# delete testtargets out of filtered train dataframe\n",
    "train4 = train.copy()\n",
    "for i in testtargets4:   #itterating through test targets\n",
    "    train4.drop(train4.loc[train4['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "# delete testtargets out of extreme abst and conc \n",
    "#for i in testtargets4:   #itterating through test targets\n",
    "#    if i in list(abst['Unnamed: 0']):\n",
    "#        abst.drop(abst.loc[abst['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "#    else:\n",
    "#        conc.drop(conc.loc[conc['Unnamed: 0']==i].index, inplace=True)  #dropping rows in df that are in test\n",
    "print('Train4 Fold: '+str(train2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e466844-6352-4697-b9bf-a950fc01abd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3514, 27607)\n",
      "(184, 27607)\n"
     ]
    }
   ],
   "source": [
    "# choosing the tetsfold for this run\n",
    "#testfold = '1'\n",
    "#testfold = '2'\n",
    "#testfold = '3'\n",
    "testfold = '4'\n",
    "\n",
    "#train = train1\n",
    "#train = train2\n",
    "#train = train3\n",
    "train = train4\n",
    "\n",
    "#test = test1\n",
    "#test = test2\n",
    "#test = test3\n",
    "test = test4\n",
    "\n",
    "#shuffle and clean train and test\n",
    "train = train.drop(['Unnamed: 0'], axis=1) #drop targets for regression \n",
    "test = test.drop(['Unnamed: 0'], axis=1) #drop targets for regression\n",
    "train = train.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "test = test.sample(frac=1).reset_index(drop=True) #shuffeling rows\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LogElasticNet_Stats.txt\", \"a\") as f:\n",
    "    print('New Version: 1-Fold - Extreme Set',file=f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (trainamount,X-1=featureamount) '+str(train.shape),file =f)\n",
    "    print('NORMnoNAtypes_'+wordclass+'_'+dataset+'_'+'1/'+str(nth)+': (testamount,X-1=featureamount) '+str(test.shape),file=f)\n",
    "    print('FoldNumber: ' + testfold,file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa06050-76ae-42e9-ad0b-e26c028fd5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concrete predictions: 131\n",
      "FINISHED :)\n"
     ]
    }
   ],
   "source": [
    "# regression: test on 1/n of dataframe and training on rest, spearmancollection for those predictions\n",
    " \n",
    "X = train[:, 1:]    #assoc vectors: predictors\n",
    "y = train[:, 0]     #CS: response variable\n",
    "y = y.astype(int)\n",
    "Xtest = test[:, 1:] #assoc vectors: predictors\n",
    "ytest = test[:, 0]  #CS: response variable\n",
    "ytest = ytest.astype(int)\n",
    "    \n",
    "# LOGISTIC REGRESSION with variable LASSO(l1) or RIDGE(l2) or ElasticNet(both) penalty\n",
    "c = [100] # high c means trust training data, low value means dont make very high values because will ot be helpful for new data (here lower C better beacuse more way more features than samples)\n",
    "l1ratio = [1]\n",
    "tol = [1e-02]\n",
    "params = [{'C': c,  \n",
    "        'l1_ratio': l1ratio,\n",
    "        'tol': tol\n",
    "        }]\n",
    "#model = Lasso(copy_X = True, tol=1e-2, max_iter = 1000, selection ='random', random_state = 1)  #define model\n",
    "model = LogisticRegression(penalty= 'elasticnet', max_iter= 1000, solver= 'saga')   # or solver='liblinear' / penalty='l1'\n",
    "    #  l1_ratio= 1,penalty= 'elasticnet' : l1_ratio =1 =LASSO, l1_ratio =0 =RIDGE, l1_ratio =0-1 ElasticNet\n",
    "    # saga solver chosen becuase support of all penalties\n",
    "\n",
    "    # grid searching through best hyperparameters, cv is set to do no crossvalidation, refit does fit the model with the best parameters so model can be used for prediction afterwards\n",
    "cv = GridSearchCV(model, param_grid = params,cv=[(slice(None), slice(None))],scoring='f1', return_train_score=False,refit=True)\n",
    "cv.fit(X,y)  \n",
    "\n",
    "# Predicting the test fold\n",
    "ymodel = cv.predict(Xtest)\n",
    "\n",
    "#performance measure \n",
    "matchesN = 0\n",
    "lableabstN = 0\n",
    "lableconcN = 0\n",
    "print('Number of concrete predictions: '+str(sum(ymodel)))\n",
    "for ind, v in enumerate(ymodel):\n",
    "    if ymodel[ind] == ytest[ind]:\n",
    "        matchesN += 1\n",
    "        if v == 0:         #counting lables of matching predictions\n",
    "            lableabstN += 1\n",
    "        else:\n",
    "            lableconcN += 1\n",
    "precision,recall,fscore,support= score(ytest,ymodel,average='macro')\n",
    "\n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/M32_noNAfinaltypes_LogElasticNet_Stats.txt\", \"a\") as f:\n",
    "#if close to -1/1 both scores are pos/neg correlating, if p-value smaller 0.05 correl statistically significant\n",
    "    print('Best Estimator: '+str(cv.best_estimator_),file=f)\n",
    "    print('Scorer: '+str(cv.scorer_),file=f)\n",
    "    print('Number of Splits: '+str(cv.n_splits_),file=f)\n",
    "    print('Number of Features: '+str(cv.n_features_in_),file=f)\n",
    "    print('Best Scores: ' + str(cv.best_score_), file=f)\n",
    "    print('Best Params: ' + str(cv.best_params_), file=f)\n",
    "    print('Seconds for Best fitting: '+str(cv.refit_time_),file=f)\n",
    "    print('Params: '+str(cv.cv_results_['params']),file=f)\n",
    "    \n",
    "    print('Matches/All predictions: ' + str(matchesN / len(ymodel)),file=f)\n",
    "    print('Matching CONC/CONCtest: '+str(lableconcN / sum(ymodel)),file=f)\n",
    "    print('Matching ABST/ABSTtest: '+str(lableabstN / (len(ymodel)-sum(ymodel))),file=f)\n",
    "    print('Mean Accuracy: ' + str(cv.score(Xtest, ytest)), file=f)\n",
    "    print('ClassifReportprecision Mean: ' + str(precision), file=f)\n",
    "    print('ClassifReportrecall Mean: ' + str(recall), file=f)\n",
    "    print('ClassifReportF1score Mean: ' + str(fscore), file=f)\n",
    "    print('R2: ' + str(cv.score(X, y)), file=f) \n",
    "    print('ClassifReport: ' + str(classification_report(ytest, ymodel, output_dict=True)), file=f)\n",
    "    print(\"--------------------------------------------------------------------\",file=f)            \n",
    "    \n",
    "    \n",
    "with open(\"/compLing/students/hiwi-theses/projects/aylin.wahl/CVRESULTSM32_noNAfinaltypes_LogElasticNet.txt\", \"a\") as f:\n",
    "    print('K-fold ElasticNet, Logistic, '+wordclass+', '+str(nth),file=f)\n",
    "    print('C: '+str(c)+', l1-ratio: '+str(l1ratio)+', tol: '+str(tol),file=f)\n",
    "    print(cv.cv_results_,file=f)\n",
    "    print('----------------------------------------------------------------------------------------------------------',file=f)\n",
    "\n",
    "\n",
    "print('FINISHED :)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b9f3d-8b94-4815-b828-a4942ce4172b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
